{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c3030bca",
      "metadata": {
        "id": "c3030bca"
      },
      "source": [
        "# Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7dce8f59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dce8f59",
        "outputId": "2071514d-21c7-4f57-ee79-2b6c656b9eca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 'NVIDIA L4')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "torch.cuda.is_available(), torch.cuda.get_device_name(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a1b0fe7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1b0fe7e",
        "outputId": "e9d4c0aa-0606-4dc6-e6c8-467e09172a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Removing existing ANeurIPS2024_SPV-MIA...\n",
            "Cloning into 'ANeurIPS2024_SPV-MIA'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 61 (delta 18), reused 25 (delta 12), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (61/61), 725.78 KiB | 27.91 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "/content/ANeurIPS2024_SPV-MIA\n"
          ]
        }
      ],
      "source": [
        "# Remove old clone\n",
        "import os, shutil\n",
        "\n",
        "repo_name = \"ANeurIPS2024_SPV-MIA\"\n",
        "if os.path.basename(os.getcwd()) == repo_name:\n",
        "    %cd ..\n",
        "if os.path.exists(repo_name):\n",
        "    print(f\"Removing existing {repo_name}...\")\n",
        "    shutil.rmtree(repo_name)\n",
        "\n",
        "# Clone fork\n",
        "!git clone https://github.com/Varzz04/ANeurIPS2024_SPV-MIA.git\n",
        "%cd ANeurIPS2024_SPV-MIA\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements-colab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2GeMmzFo6dp",
        "outputId": "f572c57c-1343-409c-88c0-ba9430dede88"
      },
      "id": "X2GeMmzFo6dp",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements-colab.txt (line 1)) (3.5.1)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (from -r requirements-colab.txt (line 2)) (0.17.0)\n",
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.11/dist-packages (from -r requirements-colab.txt (line 3)) (1.1.11)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from -r requirements-colab.txt (line 4)) (0.45.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements-colab.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements-colab.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl->-r requirements-colab.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl->-r requirements-colab.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl->-r requirements-colab.txt (line 2)) (4.51.3)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug->-r requirements-colab.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes->-r requirements-colab.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl->-r requirements-colab.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl->-r requirements-colab.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements-colab.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements-colab.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements-colab.txt (line 1)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements-colab.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements-colab.txt (line 1)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements-colab.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements-colab.txt (line 1)) (1.20.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug->-r requirements-colab.txt (line 3)) (4.13.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets->-r requirements-colab.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements-colab.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements-colab.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements-colab.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements-colab.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements-colab.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements-colab.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements-colab.txt (line 1)) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl->-r requirements-colab.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl->-r requirements-colab.txt (line 2)) (0.21.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl->-r requirements-colab.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl->-r requirements-colab.txt (line 2)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl->-r requirements-colab.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements-colab.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug->-r requirements-colab.txt (line 3)) (2.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes->-r requirements-colab.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug->-r requirements-colab.txt (line 3)) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM2g5t_go-mW",
        "outputId": "e92f1d4d-634f-4c1a-e7c4-63c1910e717a"
      },
      "id": "zM2g5t_go-mW",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.51.3\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers, trl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6c8bdc",
      "metadata": {
        "id": "0a6c8bdc"
      },
      "source": [
        "# Target Model Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "480bd020",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "480bd020",
        "outputId": "71a8a0f9-5237-42ee-edba-8198cc270524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-05-05 18:15:22.517448: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-05 18:15:22.534501: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746468922.555794    4068 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746468922.562269    4068 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-05 18:15:22.583127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 1.05k/1.05k [00:00<00:00, 7.72MB/s]\n",
            "tokenizer_config.json: 100% 234/234 [00:00<00:00, 1.80MB/s]\n",
            "vocab.json: 100% 798k/798k [00:00<00:00, 18.5MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.05MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 55.7MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 819kB/s]\n",
            "pytorch_model.bin: 100% 2.62G/2.62G [00:06<00:00, 376MB/s]\n",
            "model.safetensors:   3% 83.9M/2.62G [00:00<00:09, 274MB/s]\n",
            "generation_config.json: 100% 115/115 [00:00<00:00, 832kB/s]\n",
            "model.safetensors:   6% 168M/2.62G [00:00<00:07, 326MB/s]trainable params: 12582912 || all params: 1324208128 || trainable%: 0.9502216255842224\n",
            "model.safetensors: 100% 2.62G/2.62G [00:08<00:00, 300MB/s]\n",
            "Folder './cache/wikitext/wikitext-2-raw-v1' created.\n",
            "Packing texts in chunks of 128 tokens: 100% 33046/33046 [00:12<00:00, 2576.56 examples/s]\n",
            "Packing texts in chunks of 128 tokens: 100% 3672/3672 [00:01<00:00, 2574.92 examples/s]\n",
            "tokenizer_config.json: 100% 234/234 [00:00<00:00, 2.00MB/s]\n",
            "vocab.json: 100% 798k/798k [00:00<00:00, 16.2MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 16.7MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 9.20MB/s]\n",
            "special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 946kB/s]\n",
            "Converting train dataset to ChatML: 100% 2000/2000 [00:00<00:00, 47281.87 examples/s]\n",
            "Adding EOS to train dataset: 100% 2000/2000 [00:00<00:00, 30811.13 examples/s]\n",
            "Tokenizing train dataset: 100% 2000/2000 [00:01<00:00, 1814.60 examples/s]\n",
            "Truncating train dataset: 100% 2000/2000 [00:00<00:00, 292918.78 examples/s]\n",
            "Converting eval dataset to ChatML: 100% 500/500 [00:00<00:00, 44505.68 examples/s]\n",
            "Adding EOS to eval dataset: 100% 500/500 [00:00<00:00, 27765.45 examples/s]\n",
            "Tokenizing eval dataset: 100% 500/500 [00:00<00:00, 1768.23 examples/s]\n",
            "Truncating eval dataset: 100% 500/500 [00:00<00:00, 209422.01 examples/s]\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\n",
            "{'loss': 3.1102, 'grad_norm': 0.5014922022819519, 'learning_rate': 9.505e-05, 'epoch': 0.1}\n",
            "  5% 100/2000 [00:08<02:25, 13.09it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:03, 30.52it/s]\u001b[A\n",
            "  6% 8/125 [00:00<00:04, 25.28it/s]\u001b[A\n",
            "  9% 11/125 [00:00<00:04, 24.09it/s]\u001b[A\n",
            " 11% 14/125 [00:00<00:04, 23.39it/s]\u001b[A\n",
            " 14% 17/125 [00:00<00:04, 22.95it/s]\u001b[A\n",
            " 16% 20/125 [00:00<00:04, 22.54it/s]\u001b[A\n",
            " 18% 23/125 [00:00<00:04, 22.31it/s]\u001b[A\n",
            " 21% 26/125 [00:01<00:04, 22.38it/s]\u001b[A\n",
            " 23% 29/125 [00:01<00:04, 22.47it/s]\u001b[A\n",
            " 26% 32/125 [00:01<00:04, 22.41it/s]\u001b[A\n",
            " 28% 35/125 [00:01<00:04, 22.36it/s]\u001b[A\n",
            " 30% 38/125 [00:01<00:03, 22.34it/s]\u001b[A\n",
            " 33% 41/125 [00:01<00:03, 22.19it/s]\u001b[A\n",
            " 35% 44/125 [00:01<00:03, 22.08it/s]\u001b[A\n",
            " 38% 47/125 [00:02<00:03, 22.10it/s]\u001b[A\n",
            " 40% 50/125 [00:02<00:03, 22.21it/s]\u001b[A\n",
            " 42% 53/125 [00:02<00:03, 22.31it/s]\u001b[A\n",
            " 45% 56/125 [00:02<00:03, 22.23it/s]\u001b[A\n",
            " 47% 59/125 [00:02<00:02, 22.20it/s]\u001b[A\n",
            " 50% 62/125 [00:02<00:02, 22.18it/s]\u001b[A\n",
            " 52% 65/125 [00:02<00:02, 22.16it/s]\u001b[A\n",
            " 54% 68/125 [00:03<00:02, 22.15it/s]\u001b[A\n",
            " 57% 71/125 [00:03<00:02, 22.26it/s]\u001b[A\n",
            " 59% 74/125 [00:03<00:02, 22.29it/s]\u001b[A\n",
            " 62% 77/125 [00:03<00:02, 22.30it/s]\u001b[A\n",
            " 64% 80/125 [00:03<00:02, 22.19it/s]\u001b[A\n",
            " 66% 83/125 [00:03<00:01, 22.06it/s]\u001b[A\n",
            " 69% 86/125 [00:03<00:01, 22.03it/s]\u001b[A\n",
            " 71% 89/125 [00:03<00:01, 21.97it/s]\u001b[A\n",
            " 74% 92/125 [00:04<00:01, 22.18it/s]\u001b[A\n",
            " 76% 95/125 [00:04<00:01, 22.19it/s]\u001b[A\n",
            " 78% 98/125 [00:04<00:01, 22.13it/s]\u001b[A\n",
            " 81% 101/125 [00:04<00:01, 22.08it/s]\u001b[A\n",
            " 83% 104/125 [00:04<00:00, 22.11it/s]\u001b[A\n",
            " 86% 107/125 [00:04<00:00, 22.07it/s]\u001b[A\n",
            " 88% 110/125 [00:04<00:00, 22.02it/s]\u001b[A\n",
            " 90% 113/125 [00:05<00:00, 21.96it/s]\u001b[A\n",
            " 93% 116/125 [00:05<00:00, 21.95it/s]\u001b[A\n",
            " 95% 119/125 [00:05<00:00, 22.06it/s]\u001b[A\n",
            " 98% 122/125 [00:05<00:00, 22.11it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.9722225666046143, 'eval_runtime': 5.6324, 'eval_samples_per_second': 88.772, 'eval_steps_per_second': 22.193, 'eval_num_tokens': 25800.0, 'eval_mean_token_accuracy': 0.4324375, 'epoch': 0.1}\n",
            "  5% 100/2000 [00:14<02:25, 13.09it/s]\n",
            "100% 125/125 [00:05<00:00, 22.15it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "config.json: 100% 1.05k/1.05k [00:00<00:00, 7.86MB/s]\n",
            "{'loss': 2.9616, 'grad_norm': 0.6275987029075623, 'learning_rate': 9.005000000000001e-05, 'epoch': 0.2}\n",
            " 10% 200/2000 [00:23<02:17, 13.07it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 29.45it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.97it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.70it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 23.06it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.59it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.35it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 22.32it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 22.32it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 22.16it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 22.15it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 22.01it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.95it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 22.00it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 22.01it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 22.07it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.98it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.95it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.88it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.84it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.84it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 22.10it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 22.01it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.92it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.85it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.91it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.96it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 22.03it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 22.03it/s]\u001b[A\n",
            " 70% 88/125 [00:03<00:01, 21.97it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.85it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.87it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.89it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.90it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.97it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.94it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.90it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.85it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.82it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.82it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.78it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.9007749557495117, 'eval_runtime': 5.6959, 'eval_samples_per_second': 87.783, 'eval_steps_per_second': 21.946, 'eval_num_tokens': 51600.0, 'eval_mean_token_accuracy': 0.44321875, 'epoch': 0.2}\n",
            " 10% 200/2000 [00:28<02:17, 13.07it/s]\n",
            "100% 125/125 [00:05<00:00, 21.89it/s]\u001b[A\n",
            "{'loss': 2.8669, 'grad_norm': 0.5659433007240295, 'learning_rate': 8.505000000000001e-05, 'epoch': 0.3}\n",
            " 15% 300/2000 [00:37<02:08, 13.21it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.93it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.69it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.24it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.64it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.30it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.07it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.99it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 22.02it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 22.01it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.82it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.80it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.69it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.67it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.63it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.67it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.70it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.61it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.56it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.58it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.50it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.55it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.63it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.54it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.46it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.47it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.56it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.60it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.58it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.61it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.67it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.55it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.61it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.56it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.64it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.65it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.8778634071350098, 'eval_runtime': 5.7756, 'eval_samples_per_second': 86.571, 'eval_steps_per_second': 21.643, 'eval_num_tokens': 77400.0, 'eval_mean_token_accuracy': 0.445046875, 'epoch': 0.3}\n",
            " 15% 300/2000 [00:43<02:08, 13.21it/s]\n",
            "100% 125/125 [00:05<00:00, 21.65it/s]\u001b[A\n",
            "{'loss': 2.8521, 'grad_norm': 0.6312571167945862, 'learning_rate': 8.005000000000001e-05, 'epoch': 0.4}\n",
            " 20% 400/2000 [00:51<02:00, 13.26it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.13it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.78it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.79it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.23it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.93it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.68it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.66it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.59it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.56it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.58it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.50it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.33it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.37it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.41it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.38it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.38it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.42it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.40it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.38it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.36it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.34it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.11it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.30it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.35it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.25it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.17it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.22it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.25it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.31it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.36it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.38it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.31it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.27it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.28it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.25it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.34it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.39it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.45it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.39it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.8661727905273438, 'eval_runtime': 5.8586, 'eval_samples_per_second': 85.344, 'eval_steps_per_second': 21.336, 'eval_num_tokens': 103200.0, 'eval_mean_token_accuracy': 0.445265625, 'epoch': 0.4}\n",
            " 20% 400/2000 [00:57<02:00, 13.26it/s]\n",
            "100% 125/125 [00:05<00:00, 21.32it/s]\u001b[A\n",
            "{'loss': 2.8532, 'grad_norm': 0.6310346126556396, 'learning_rate': 7.505e-05, 'epoch': 0.5}\n",
            " 25% 500/2000 [01:05<01:59, 12.60it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.61it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.78it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.55it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 21.94it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:05, 21.61it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.51it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.56it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.56it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.49it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.40it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.13it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.00it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:04, 21.12it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.10it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.22it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.28it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.23it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.19it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.30it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.28it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.37it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.35it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.33it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.32it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.07it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.19it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.24it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.38it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.34it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.25it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.22it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.19it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.11it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.17it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.28it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.25it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.31it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.30it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.32it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.32it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.8546416759490967, 'eval_runtime': 5.8834, 'eval_samples_per_second': 84.984, 'eval_steps_per_second': 21.246, 'eval_num_tokens': 129000.0, 'eval_mean_token_accuracy': 0.44734375, 'epoch': 0.5}\n",
            " 25% 500/2000 [01:11<01:59, 12.60it/s]\n",
            "100% 125/125 [00:05<00:00, 21.36it/s]\u001b[A\n",
            "{'loss': 2.7596, 'grad_norm': 0.5455775856971741, 'learning_rate': 7.005000000000001e-05, 'epoch': 0.6}\n",
            " 30% 600/2000 [01:19<01:46, 13.17it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.28it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.80it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.73it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.27it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.06it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.84it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.79it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.60it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.26it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.27it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.26it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.36it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.39it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.44it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.38it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.21it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.27it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.32it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.43it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.51it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.54it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.49it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.44it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.41it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.30it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.36it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.47it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.42it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.27it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.40it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.41it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.50it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.849743127822876, 'eval_runtime': 5.8408, 'eval_samples_per_second': 85.605, 'eval_steps_per_second': 21.401, 'eval_num_tokens': 154800.0, 'eval_mean_token_accuracy': 0.447609375, 'epoch': 0.6}\n",
            " 30% 600/2000 [01:25<01:46, 13.17it/s]\n",
            "100% 125/125 [00:05<00:00, 21.42it/s]\u001b[A\n",
            "{'loss': 2.8103, 'grad_norm': 0.6583347320556641, 'learning_rate': 6.505e-05, 'epoch': 0.7}\n",
            " 35% 700/2000 [01:34<01:39, 13.11it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.05it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.45it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.03it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.22it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.90it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.85it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.88it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.81it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.78it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.68it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.61it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.57it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.50it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.63it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.64it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.67it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.61it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.68it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.66it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.64it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.68it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.73it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.74it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.66it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.64it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.56it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.50it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.48it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.42it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.45it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.51it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.57it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.60it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.57it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.8438432216644287, 'eval_runtime': 5.795, 'eval_samples_per_second': 86.282, 'eval_steps_per_second': 21.571, 'eval_num_tokens': 180600.0, 'eval_mean_token_accuracy': 0.448265625, 'epoch': 0.7}\n",
            " 35% 700/2000 [01:40<01:39, 13.11it/s]\n",
            "100% 125/125 [00:05<00:00, 21.57it/s]\u001b[A\n",
            "{'loss': 2.8195, 'grad_norm': 0.5784714818000793, 'learning_rate': 6.005000000000001e-05, 'epoch': 0.8}\n",
            " 40% 800/2000 [01:48<01:30, 13.28it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.99it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.57it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.11it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.56it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.24it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.03it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.98it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.94it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.88it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.71it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.70it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.66it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.70it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.73it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.72it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.66it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.64it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.67it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.61it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.58it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.62it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.74it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.69it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.56it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.60it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.56it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.61it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.61it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.64it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.67it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.42it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.51it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.55it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.51it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.44it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.55it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.844998359680176, 'eval_runtime': 5.7801, 'eval_samples_per_second': 86.504, 'eval_steps_per_second': 21.626, 'eval_num_tokens': 206400.0, 'eval_mean_token_accuracy': 0.4486875, 'epoch': 0.8}\n",
            " 40% 800/2000 [01:54<01:30, 13.28it/s]\n",
            "100% 125/125 [00:05<00:00, 21.61it/s]\u001b[A\n",
            "{'loss': 2.785, 'grad_norm': 0.6540568470954895, 'learning_rate': 5.505e-05, 'epoch': 0.9}\n",
            " 45% 900/2000 [02:02<01:25, 12.82it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.81it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.33it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.05it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.13it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:05, 21.69it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.67it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.84it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.90it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.81it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.72it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.51it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.35it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.45it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.57it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.66it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.52it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.43it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.41it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.39it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.44it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.51it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.54it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.41it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.49it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.55it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.55it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.48it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.50it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.52it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.55it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.52it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.44it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.8376026153564453, 'eval_runtime': 5.8139, 'eval_samples_per_second': 86.001, 'eval_steps_per_second': 21.5, 'eval_num_tokens': 232200.0, 'eval_mean_token_accuracy': 0.449484375, 'epoch': 0.9}\n",
            " 45% 900/2000 [02:08<01:25, 12.82it/s]\n",
            "100% 125/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            "{'loss': 2.745, 'grad_norm': 0.6879851818084717, 'learning_rate': 5.005e-05, 'epoch': 1.0}\n",
            " 50% 1000/2000 [02:16<01:15, 13.26it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.50it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.81it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.41it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.03it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.81it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.68it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.73it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.66it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.51it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.39it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.43it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.46it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.52it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.47it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.41it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.31it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.29it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.37it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.56it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.55it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.39it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.45it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.39it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.39it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.42it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.36it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.35it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.39it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.33it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.38it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.36it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.8373968601226807, 'eval_runtime': 5.843, 'eval_samples_per_second': 85.573, 'eval_steps_per_second': 21.393, 'eval_num_tokens': 258000.0, 'eval_mean_token_accuracy': 0.449421875, 'epoch': 1.0}\n",
            " 50% 1000/2000 [02:22<01:15, 13.26it/s]\n",
            "100% 125/125 [00:05<00:00, 21.33it/s]\u001b[A\n",
            "{'loss': 2.7585, 'grad_norm': 0.582949161529541, 'learning_rate': 4.5050000000000004e-05, 'epoch': 1.1}\n",
            " 55% 1100/2000 [02:31<01:09, 12.93it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.60it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.22it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.01it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.12it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:05, 21.78it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.67it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.72it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.68it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.62it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.63it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.53it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.44it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.43it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.46it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.46it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.50it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.52it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.44it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.34it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.37it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.39it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.41it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.37it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.32it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.29it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.23it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.32it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.38it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.31it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.23it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.23it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.28it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.43it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.51it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.51it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.57it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.40it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.31it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.83918833732605, 'eval_runtime': 5.8455, 'eval_samples_per_second': 85.535, 'eval_steps_per_second': 21.384, 'eval_num_tokens': 283800.0, 'eval_mean_token_accuracy': 0.449953125, 'epoch': 1.1}\n",
            " 55% 1100/2000 [02:37<01:09, 12.93it/s]\n",
            "100% 125/125 [00:05<00:00, 21.33it/s]\u001b[A\n",
            "{'loss': 2.7491, 'grad_norm': 0.6938503980636597, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.2}\n",
            " 60% 1200/2000 [02:45<00:59, 13.40it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.47it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.44it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.06it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.38it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.06it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.80it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.78it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.76it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.69it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.54it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.53it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.47it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.37it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.42it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.43it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.45it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.41it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.30it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.21it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.32it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.39it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.35it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.38it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.41it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.26it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.22it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.38it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.35it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.32it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.26it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.30it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.40it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.36it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.41it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.40it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.8430991172790527, 'eval_runtime': 5.839, 'eval_samples_per_second': 85.631, 'eval_steps_per_second': 21.408, 'eval_num_tokens': 309600.0, 'eval_mean_token_accuracy': 0.448015625, 'epoch': 1.2}\n",
            " 60% 1200/2000 [02:51<00:59, 13.40it/s]\n",
            "100% 125/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            "{'loss': 2.6481, 'grad_norm': 0.7965344190597534, 'learning_rate': 3.505e-05, 'epoch': 1.3}\n",
            " 65% 1300/2000 [02:59<00:52, 13.25it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.56it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.78it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.57it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.07it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.81it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.66it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.74it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.57it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.55it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.55it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.54it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.42it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.39it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.43it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.44it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.54it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.64it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.60it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.64it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.74it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.69it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.34it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.52it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.34it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.42it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.38it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.33it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.47it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.41it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.33it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.8457510471343994, 'eval_runtime': 5.8321, 'eval_samples_per_second': 85.732, 'eval_steps_per_second': 21.433, 'eval_num_tokens': 335400.0, 'eval_mean_token_accuracy': 0.4480625, 'epoch': 1.3}\n",
            " 65% 1300/2000 [03:05<00:52, 13.25it/s]\n",
            "100% 125/125 [00:05<00:00, 21.34it/s]\u001b[A\n",
            "{'loss': 2.6722, 'grad_norm': 0.9650287628173828, 'learning_rate': 3.0050000000000002e-05, 'epoch': 1.4}\n",
            " 70% 1400/2000 [03:13<00:45, 13.27it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.17it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.09it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.94it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.42it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.25it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.04it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.95it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.84it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.60it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.43it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.39it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.47it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.54it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.62it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.60it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.31it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.39it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.38it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.46it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.55it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.60it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.47it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.47it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.53it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.58it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.58it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.62it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.56it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.57it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.60it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.42it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.41it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.84489107131958, 'eval_runtime': 5.812, 'eval_samples_per_second': 86.03, 'eval_steps_per_second': 21.507, 'eval_num_tokens': 361200.0, 'eval_mean_token_accuracy': 0.44915625, 'epoch': 1.4}\n",
            " 70% 1400/2000 [03:19<00:45, 13.27it/s]\n",
            "100% 125/125 [00:05<00:00, 21.46it/s]\u001b[A\n",
            "{'loss': 2.6905, 'grad_norm': 0.8760926127433777, 'learning_rate': 2.5050000000000002e-05, 'epoch': 1.5}\n",
            " 75% 1500/2000 [03:27<00:37, 13.25it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.57it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.71it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.57it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.09it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.96it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.84it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.87it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.88it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.69it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.62it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.41it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.51it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.47it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.54it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.61it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.46it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.56it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.51it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.47it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.48it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.58it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.56it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.51it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.48it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.45it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.52it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.52it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.52it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.44it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.843940496444702, 'eval_runtime': 5.8142, 'eval_samples_per_second': 85.996, 'eval_steps_per_second': 21.499, 'eval_num_tokens': 387000.0, 'eval_mean_token_accuracy': 0.44903125, 'epoch': 1.5}\n",
            " 75% 1500/2000 [03:33<00:37, 13.25it/s]\n",
            "100% 125/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            "{'loss': 2.6806, 'grad_norm': 0.774131715297699, 'learning_rate': 2.0050000000000003e-05, 'epoch': 1.6}\n",
            " 80% 1600/2000 [03:41<00:29, 13.57it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.88it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.52it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.03it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.38it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.17it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.89it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.92it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.92it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.80it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.61it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.49it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.46it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.42it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.54it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.63it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.66it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.55it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.53it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.50it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.50it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.56it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.52it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.49it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.53it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.61it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.62it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.63it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.57it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.67it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.74it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.56it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.58it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.8440184593200684, 'eval_runtime': 5.799, 'eval_samples_per_second': 86.222, 'eval_steps_per_second': 21.555, 'eval_num_tokens': 412800.0, 'eval_mean_token_accuracy': 0.449171875, 'epoch': 1.6}\n",
            " 80% 1600/2000 [03:47<00:29, 13.57it/s]\n",
            "100% 125/125 [00:05<00:00, 21.56it/s]\u001b[A\n",
            "{'loss': 2.6951, 'grad_norm': 0.6522031426429749, 'learning_rate': 1.505e-05, 'epoch': 1.7}\n",
            " 85% 1700/2000 [03:55<00:22, 13.18it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.12it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.23it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.96it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.38it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.87it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.72it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.71it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.71it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.67it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.63it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.57it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.48it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.51it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.59it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.56it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.60it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.57it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.59it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.53it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.62it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.53it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.48it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.32it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.42it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.46it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.47it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.42it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.840475082397461, 'eval_runtime': 5.8138, 'eval_samples_per_second': 86.003, 'eval_steps_per_second': 21.501, 'eval_num_tokens': 438600.0, 'eval_mean_token_accuracy': 0.44921875, 'epoch': 1.7}\n",
            " 85% 1700/2000 [04:01<00:22, 13.18it/s]\n",
            "100% 125/125 [00:05<00:00, 21.45it/s]\u001b[A\n",
            "{'loss': 2.7452, 'grad_norm': 0.7217880487442017, 'learning_rate': 1.005e-05, 'epoch': 1.8}\n",
            " 90% 1800/2000 [04:10<00:14, 13.48it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.63it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.45it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.98it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.41it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.06it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.86it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.80it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.68it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.54it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.56it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.54it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.52it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.58it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.59it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.56it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.55it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.49it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.51it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.52it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.56it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.58it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.52it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.57it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.56it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.54it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.59it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.56it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.58it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.52it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.58it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.52it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.51it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.46it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.8423354625701904, 'eval_runtime': 5.8046, 'eval_samples_per_second': 86.138, 'eval_steps_per_second': 21.535, 'eval_num_tokens': 464400.0, 'eval_mean_token_accuracy': 0.44946875, 'epoch': 1.8}\n",
            " 90% 1800/2000 [04:15<00:14, 13.48it/s]\n",
            "100% 125/125 [00:05<00:00, 21.52it/s]\u001b[A\n",
            "{'loss': 2.7598, 'grad_norm': 0.8189331293106079, 'learning_rate': 5.050000000000001e-06, 'epoch': 1.9}\n",
            " 95% 1900/2000 [04:24<00:07, 13.18it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.69it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.44it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.08it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.50it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.05it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.85it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.82it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.80it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.78it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.66it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.58it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.28it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.35it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.42it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.35it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.42it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.45it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.32it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.41it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.44it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.52it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.42it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.53it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.59it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.59it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.58it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.59it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.48it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.46it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.40it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.38it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.39it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.8411366939544678, 'eval_runtime': 5.8204, 'eval_samples_per_second': 85.905, 'eval_steps_per_second': 21.476, 'eval_num_tokens': 490200.0, 'eval_mean_token_accuracy': 0.44915625, 'epoch': 1.9}\n",
            " 95% 1900/2000 [04:30<00:07, 13.18it/s]\n",
            "100% 125/125 [00:05<00:00, 21.42it/s]\u001b[A\n",
            "{'loss': 2.7051, 'grad_norm': 0.6468682885169983, 'learning_rate': 5.0000000000000004e-08, 'epoch': 2.0}\n",
            "100% 2000/2000 [04:38<00:00, 13.00it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 29.08it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.40it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.99it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.28it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.80it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.60it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.57it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.63it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.60it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.53it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.49it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.24it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:04, 21.18it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.36it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.41it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.46it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.25it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.13it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.13it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.28it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.32it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.33it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.37it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.38it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.42it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.42it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.22it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.23it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.30it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.26it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.29it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.36it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.38it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.24it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.8402631282806396, 'eval_runtime': 5.8593, 'eval_samples_per_second': 85.335, 'eval_steps_per_second': 21.334, 'eval_num_tokens': 516000.0, 'eval_mean_token_accuracy': 0.4491875, 'epoch': 2.0}\n",
            "100% 2000/2000 [04:44<00:00, 13.00it/s]\n",
            "100% 125/125 [00:05<00:00, 21.15it/s]\u001b[A\n",
            "{'train_runtime': 285.1638, 'train_samples_per_second': 14.027, 'train_steps_per_second': 7.014, 'train_loss': 2.783376998901367, 'num_tokens': 516000.0, 'mean_token_accuracy': 0.446087890625, 'epoch': 2.0}\n",
            "100% 2000/2000 [04:45<00:00,  7.01it/s]\n"
          ]
        }
      ],
      "source": [
        "# Launch fine-tuning test using a smaller falcon model and small wikitext-2-raw-v1 slice\n",
        "!accelerate launch ./ft_llms/llms_finetune.py \\\n",
        "--output_dir ./ft_llms/falcon/wikitext/target/ \\\n",
        "--block_size 128 --eval_steps 100 --save_epochs 100 --log_steps 100 \\\n",
        "-d wikitext -m tiiuae/falcon-rw-1b --packing --use_dataset_cache \\\n",
        "-e 2 -b 2 -lr 1e-4 --gradient_accumulation_steps 1 \\\n",
        "--train_sta_idx=0 --train_end_idx=2000 --eval_sta_idx=0 --eval_end_idx=500 \\\n",
        "--dataset_config_name wikitext-2-raw-v1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-prompt Reference Model Fine-tuning"
      ],
      "metadata": {
        "id": "0vcFz6ac9c-7"
      },
      "id": "0vcFz6ac9c-7"
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch ./ft_llms/refer_data_generate.py \\\n",
        "-tm ./ft_llms/falcon/wikitext/target/ \\\n",
        "-m tiiuae/falcon-rw-1b -d wikitext \\\n",
        "--dataset_config_name wikitext-2-raw-v1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu04XTaI9gnm",
        "outputId": "280dff35-e0d4-4741-9e60-14c25b960aec"
      },
      "id": "nu04XTaI9gnm",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA streamkimeneten csak az utolsó 5000 sor látható.\u001b[0m\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4920/6585 [2:59:27<1:00:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4921/6585 [2:59:29<1:00:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4922/6585 [2:59:32<1:00:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4923/6585 [2:59:34<1:00:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4924/6585 [2:59:36<1:00:53,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4925/6585 [2:59:38<1:00:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4926/6585 [2:59:40<1:00:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4927/6585 [2:59:43<1:00:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4928/6585 [2:59:45<1:00:06,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4929/6585 [2:59:47<1:00:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4930/6585 [2:59:49<1:00:18,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4931/6585 [2:59:51<1:00:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4932/6585 [2:59:54<1:00:18,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4933/6585 [2:59:56<1:00:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4934/6585 [2:59:58<1:00:24,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4935/6585 [3:00:00<1:00:14,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4936/6585 [3:00:02<1:00:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4937/6585 [3:00:04<59:54,  2.18s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4938/6585 [3:00:07<59:54,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4939/6585 [3:00:09<1:00:15,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4940/6585 [3:00:11<1:00:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4941/6585 [3:00:13<59:56,  2.19s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4942/6585 [3:00:15<59:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4943/6585 [3:00:18<59:42,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4944/6585 [3:00:20<59:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4945/6585 [3:00:22<1:00:24,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4946/6585 [3:00:24<1:00:02,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4947/6585 [3:00:26<59:49,  2.19s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4948/6585 [3:00:29<59:42,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4949/6585 [3:00:31<59:36,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4950/6585 [3:00:33<59:49,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4951/6585 [3:00:35<59:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4952/6585 [3:00:37<59:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4953/6585 [3:00:39<59:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4954/6585 [3:00:42<59:02,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4955/6585 [3:00:44<59:30,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4956/6585 [3:00:46<59:36,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4957/6585 [3:00:48<59:34,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4958/6585 [3:00:50<59:19,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4959/6585 [3:00:53<59:18,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4960/6585 [3:00:55<59:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4961/6585 [3:00:57<59:19,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4962/6585 [3:00:59<59:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4963/6585 [3:01:01<59:05,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4964/6585 [3:01:04<59:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4965/6585 [3:01:06<59:16,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4966/6585 [3:01:08<59:09,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4967/6585 [3:01:10<59:01,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4968/6585 [3:01:12<58:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4969/6585 [3:01:14<58:46,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4970/6585 [3:01:17<59:06,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 75% 4971/6585 [3:01:19<58:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4972/6585 [3:01:21<58:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4973/6585 [3:01:23<58:24,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4974/6585 [3:01:25<58:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4975/6585 [3:01:28<58:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4976/6585 [3:01:30<58:46,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(0.6847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4977/6585 [3:01:32<58:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4978/6585 [3:01:34<58:37,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4979/6585 [3:01:36<58:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4980/6585 [3:01:39<58:41,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4981/6585 [3:01:41<58:44,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4982/6585 [3:01:43<58:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4983/6585 [3:01:45<58:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4984/6585 [3:01:47<58:12,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4985/6585 [3:01:49<58:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4986/6585 [3:01:52<58:42,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4987/6585 [3:01:54<58:37,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4988/6585 [3:01:56<58:30,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4989/6585 [3:01:58<58:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4990/6585 [3:02:00<58:14,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4991/6585 [3:02:03<58:19,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4992/6585 [3:02:05<58:20,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4993/6585 [3:02:07<58:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4994/6585 [3:02:09<57:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4995/6585 [3:02:11<58:01,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4996/6585 [3:02:14<58:26,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4997/6585 [3:02:16<58:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4998/6585 [3:02:18<58:10,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 4999/6585 [3:02:20<57:52,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5000/6585 [3:02:22<57:41,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5001/6585 [3:02:25<57:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5002/6585 [3:02:27<57:51,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5003/6585 [3:02:29<57:41,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5004/6585 [3:02:31<57:26,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5005/6585 [3:02:33<57:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5006/6585 [3:02:35<57:37,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5007/6585 [3:02:38<57:26,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5008/6585 [3:02:40<57:28,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5009/6585 [3:02:42<57:24,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5010/6585 [3:02:44<57:21,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5011/6585 [3:02:46<57:37,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5012/6585 [3:02:49<57:35,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5013/6585 [3:02:51<57:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5014/6585 [3:02:53<57:16,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5015/6585 [3:02:55<57:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5016/6585 [3:02:57<57:09,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5017/6585 [3:03:00<57:12,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5018/6585 [3:03:02<56:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5019/6585 [3:03:04<56:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5020/6585 [3:03:06<56:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5021/6585 [3:03:08<56:43,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5022/6585 [3:03:10<57:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5023/6585 [3:03:13<56:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5024/6585 [3:03:15<56:56,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5025/6585 [3:03:17<56:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5026/6585 [3:03:19<56:58,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5027/6585 [3:03:21<57:11,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5028/6585 [3:03:24<56:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5029/6585 [3:03:26<56:49,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5030/6585 [3:03:28<56:44,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5031/6585 [3:03:30<56:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5032/6585 [3:03:32<56:57,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5033/6585 [3:03:35<56:43,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5034/6585 [3:03:37<56:45,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5035/6585 [3:03:39<56:34,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5036/6585 [3:03:41<56:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 76% 5037/6585 [3:03:43<56:36,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5038/6585 [3:03:46<56:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5039/6585 [3:03:48<56:28,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5040/6585 [3:03:50<56:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5041/6585 [3:03:52<56:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5042/6585 [3:03:54<56:42,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5043/6585 [3:03:57<56:30,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5044/6585 [3:03:59<56:23,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5045/6585 [3:04:01<56:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5046/6585 [3:04:03<56:00,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.3777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5047/6585 [3:04:05<55:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5048/6585 [3:04:07<56:28,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5049/6585 [3:04:10<56:23,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5050/6585 [3:04:12<56:12,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5051/6585 [3:04:14<56:25,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5052/6585 [3:04:16<56:08,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5053/6585 [3:04:19<56:22,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5054/6585 [3:04:21<56:07,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5055/6585 [3:04:23<56:09,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5056/6585 [3:04:25<55:52,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5057/6585 [3:04:27<55:39,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5058/6585 [3:04:29<55:49,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5059/6585 [3:04:32<55:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5060/6585 [3:04:34<55:46,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5061/6585 [3:04:36<55:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5062/6585 [3:04:38<55:28,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5063/6585 [3:04:40<55:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5064/6585 [3:04:43<55:24,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5065/6585 [3:04:45<55:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5066/6585 [3:04:47<55:17,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5067/6585 [3:04:49<55:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5068/6585 [3:04:51<55:12,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5069/6585 [3:04:53<55:00,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5070/6585 [3:04:56<55:02,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5071/6585 [3:04:58<55:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5072/6585 [3:05:00<55:00,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5073/6585 [3:05:02<55:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5074/6585 [3:05:04<55:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5075/6585 [3:05:07<54:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5076/6585 [3:05:09<54:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5077/6585 [3:05:11<54:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5078/6585 [3:05:13<54:49,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5079/6585 [3:05:15<54:52,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5080/6585 [3:05:17<54:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5081/6585 [3:05:20<54:45,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5082/6585 [3:05:22<54:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5083/6585 [3:05:24<54:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5084/6585 [3:05:26<54:20,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5085/6585 [3:05:28<54:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5086/6585 [3:05:31<54:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5087/6585 [3:05:33<54:24,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5088/6585 [3:05:35<54:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5089/6585 [3:05:37<54:12,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5090/6585 [3:05:39<54:11,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5091/6585 [3:05:41<54:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5092/6585 [3:05:44<54:06,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5093/6585 [3:05:46<54:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5094/6585 [3:05:48<53:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5095/6585 [3:05:50<53:51,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5096/6585 [3:05:52<53:57,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5097/6585 [3:05:54<53:55,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5098/6585 [3:05:57<53:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5099/6585 [3:05:59<53:48,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5100/6585 [3:06:01<53:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5101/6585 [3:06:03<53:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5102/6585 [3:06:05<53:50,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 77% 5103/6585 [3:06:08<53:50,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5104/6585 [3:06:10<53:57,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5105/6585 [3:06:12<53:45,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5106/6585 [3:06:14<54:01,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5107/6585 [3:06:16<54:03,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5108/6585 [3:06:18<53:47,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5109/6585 [3:06:21<53:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5110/6585 [3:06:23<53:17,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5111/6585 [3:06:25<53:12,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.4524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5112/6585 [3:06:27<53:07,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5113/6585 [3:06:29<53:04,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5114/6585 [3:06:31<52:55,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5115/6585 [3:06:34<52:58,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5116/6585 [3:06:36<52:55,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5117/6585 [3:06:38<52:54,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5118/6585 [3:06:40<53:08,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5119/6585 [3:06:42<53:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5120/6585 [3:06:44<53:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5121/6585 [3:06:47<53:03,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5122/6585 [3:06:49<53:02,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5123/6585 [3:06:51<53:02,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5124/6585 [3:06:53<52:57,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5125/6585 [3:06:55<52:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5126/6585 [3:06:57<52:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5127/6585 [3:07:00<52:58,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5128/6585 [3:07:02<52:51,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5129/6585 [3:07:04<52:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5130/6585 [3:07:06<52:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5131/6585 [3:07:08<52:51,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5132/6585 [3:07:11<52:41,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5133/6585 [3:07:13<52:30,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5134/6585 [3:07:15<52:19,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5135/6585 [3:07:17<52:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.6770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5136/6585 [3:07:19<52:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5137/6585 [3:07:21<52:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5138/6585 [3:07:24<52:24,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5139/6585 [3:07:26<52:15,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5140/6585 [3:07:28<52:07,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5141/6585 [3:07:30<52:09,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5142/6585 [3:07:32<52:07,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5143/6585 [3:07:34<52:26,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5144/6585 [3:07:37<52:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5145/6585 [3:07:39<52:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5146/6585 [3:07:41<52:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5147/6585 [3:07:43<52:10,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5148/6585 [3:07:45<52:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5149/6585 [3:07:48<52:01,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5150/6585 [3:07:50<52:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5151/6585 [3:07:52<51:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5152/6585 [3:07:54<51:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5153/6585 [3:07:56<51:50,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5154/6585 [3:07:58<51:51,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5155/6585 [3:08:01<51:46,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5156/6585 [3:08:03<51:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5157/6585 [3:08:05<51:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5158/6585 [3:08:07<51:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5159/6585 [3:08:09<51:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5160/6585 [3:08:11<51:29,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5161/6585 [3:08:14<51:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5162/6585 [3:08:16<51:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5163/6585 [3:08:18<51:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5164/6585 [3:08:20<51:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5165/6585 [3:08:22<51:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5166/6585 [3:08:24<51:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5167/6585 [3:08:27<51:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5168/6585 [3:08:29<51:13,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 78% 5169/6585 [3:08:31<51:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5170/6585 [3:08:33<50:53,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5171/6585 [3:08:35<50:49,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5172/6585 [3:08:37<50:50,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5173/6585 [3:08:40<50:56,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5174/6585 [3:08:42<50:54,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5175/6585 [3:08:44<50:52,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5176/6585 [3:08:46<50:48,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5177/6585 [3:08:48<50:51,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5178/6585 [3:08:50<50:46,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5179/6585 [3:08:53<50:50,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5180/6585 [3:08:55<50:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5181/6585 [3:08:57<50:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5182/6585 [3:08:59<50:51,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5183/6585 [3:09:01<50:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5184/6585 [3:09:03<50:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5185/6585 [3:09:06<50:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5186/6585 [3:09:08<50:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5187/6585 [3:09:10<50:41,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5188/6585 [3:09:12<50:45,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5189/6585 [3:09:14<50:42,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5190/6585 [3:09:17<50:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5191/6585 [3:09:19<50:32,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5192/6585 [3:09:21<50:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5193/6585 [3:09:23<50:32,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5194/6585 [3:09:25<50:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5195/6585 [3:09:27<50:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5196/6585 [3:09:30<50:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5197/6585 [3:09:32<50:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5198/6585 [3:09:34<50:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5199/6585 [3:09:36<50:04,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5200/6585 [3:09:38<49:55,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5201/6585 [3:09:40<49:43,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5202/6585 [3:09:43<49:46,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5203/6585 [3:09:45<49:58,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5204/6585 [3:09:47<50:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5205/6585 [3:09:49<50:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5206/6585 [3:09:51<49:57,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5207/6585 [3:09:53<49:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5208/6585 [3:09:56<49:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5209/6585 [3:09:58<49:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5210/6585 [3:10:00<49:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5211/6585 [3:10:02<49:48,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5212/6585 [3:10:04<49:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5213/6585 [3:10:07<49:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5214/6585 [3:10:09<49:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5215/6585 [3:10:11<50:05,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5216/6585 [3:10:13<49:57,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5217/6585 [3:10:15<49:51,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5218/6585 [3:10:17<49:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5219/6585 [3:10:20<49:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5220/6585 [3:10:22<49:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5221/6585 [3:10:24<49:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5222/6585 [3:10:26<49:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5223/6585 [3:10:28<49:20,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5224/6585 [3:10:30<49:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5225/6585 [3:10:33<49:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5226/6585 [3:10:35<49:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5227/6585 [3:10:37<49:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5228/6585 [3:10:39<49:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5229/6585 [3:10:41<49:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5230/6585 [3:10:44<49:06,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5231/6585 [3:10:46<49:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5232/6585 [3:10:48<48:59,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5233/6585 [3:10:50<49:00,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5234/6585 [3:10:52<48:46,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 79% 5235/6585 [3:10:54<48:50,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5236/6585 [3:10:57<48:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5237/6585 [3:10:59<48:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5238/6585 [3:11:01<48:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5239/6585 [3:11:03<48:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5240/6585 [3:11:05<48:56,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5241/6585 [3:11:07<48:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5242/6585 [3:11:10<48:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5243/6585 [3:11:12<48:42,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5244/6585 [3:11:14<48:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5245/6585 [3:11:16<48:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5246/6585 [3:11:18<48:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5247/6585 [3:11:21<48:44,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5248/6585 [3:11:23<48:43,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5249/6585 [3:11:25<48:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5250/6585 [3:11:27<48:42,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5251/6585 [3:11:29<48:41,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5252/6585 [3:11:32<48:54,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5253/6585 [3:11:34<48:56,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5254/6585 [3:11:36<48:46,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5255/6585 [3:11:38<48:50,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5256/6585 [3:11:40<48:41,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5257/6585 [3:11:43<48:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5258/6585 [3:11:45<48:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5259/6585 [3:11:47<48:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5260/6585 [3:11:49<48:29,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5261/6585 [3:11:51<48:22,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5262/6585 [3:11:53<48:18,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5263/6585 [3:11:56<48:17,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5264/6585 [3:11:58<48:07,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5265/6585 [3:12:00<48:05,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5266/6585 [3:12:02<48:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.1007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5267/6585 [3:12:04<47:56,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5268/6585 [3:12:07<47:49,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5269/6585 [3:12:09<47:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5270/6585 [3:12:11<47:42,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5271/6585 [3:12:13<47:38,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5272/6585 [3:12:15<47:29,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5273/6585 [3:12:17<47:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5274/6585 [3:12:20<47:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5275/6585 [3:12:22<47:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5276/6585 [3:12:24<47:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5277/6585 [3:12:26<47:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5278/6585 [3:12:28<47:22,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5279/6585 [3:12:30<47:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5280/6585 [3:12:33<47:37,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5281/6585 [3:12:35<47:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5282/6585 [3:12:37<47:30,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5283/6585 [3:12:39<47:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5284/6585 [3:12:41<47:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5285/6585 [3:12:44<47:19,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5286/6585 [3:12:46<47:24,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5287/6585 [3:12:48<47:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5288/6585 [3:12:50<47:11,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5289/6585 [3:12:52<46:58,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5290/6585 [3:12:55<47:02,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5291/6585 [3:12:57<47:17,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5292/6585 [3:12:59<47:10,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5293/6585 [3:13:01<47:07,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5294/6585 [3:13:03<46:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5295/6585 [3:13:05<46:43,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5296/6585 [3:13:08<46:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5297/6585 [3:13:10<46:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5298/6585 [3:13:12<46:33,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5299/6585 [3:13:14<46:25,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 80% 5300/6585 [3:13:16<46:21,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5301/6585 [3:13:18<46:22,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5302/6585 [3:13:21<46:20,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5303/6585 [3:13:23<46:31,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5304/6585 [3:13:25<46:41,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5305/6585 [3:13:27<46:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5306/6585 [3:13:29<46:31,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5307/6585 [3:13:32<46:43,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5308/6585 [3:13:34<46:49,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5309/6585 [3:13:36<46:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5310/6585 [3:13:38<46:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5311/6585 [3:13:40<46:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5312/6585 [3:13:43<46:49,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5313/6585 [3:13:45<46:43,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5314/6585 [3:13:47<46:38,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5315/6585 [3:13:49<46:30,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5316/6585 [3:13:51<46:26,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5317/6585 [3:13:54<46:30,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5318/6585 [3:13:56<46:23,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5319/6585 [3:13:58<46:13,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5320/6585 [3:14:00<46:25,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5321/6585 [3:14:02<46:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5322/6585 [3:14:05<46:22,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5323/6585 [3:14:07<46:20,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5324/6585 [3:14:09<46:10,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5325/6585 [3:14:11<46:21,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5326/6585 [3:14:13<46:13,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5327/6585 [3:14:16<46:33,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5328/6585 [3:14:18<46:35,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5329/6585 [3:14:20<46:31,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5330/6585 [3:14:22<46:12,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5331/6585 [3:14:24<45:58,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5332/6585 [3:14:27<46:00,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5333/6585 [3:14:29<45:49,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5334/6585 [3:14:31<45:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5335/6585 [3:14:33<45:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5336/6585 [3:14:35<45:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5337/6585 [3:14:38<45:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5338/6585 [3:14:40<45:56,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5339/6585 [3:14:42<45:48,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5340/6585 [3:14:44<45:34,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5341/6585 [3:14:46<45:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5342/6585 [3:14:49<45:28,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5343/6585 [3:14:51<45:34,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5344/6585 [3:14:53<45:19,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5345/6585 [3:14:55<45:14,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5346/6585 [3:14:57<45:03,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5347/6585 [3:15:00<45:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5348/6585 [3:15:02<45:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5349/6585 [3:15:04<45:07,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5350/6585 [3:15:06<44:49,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5351/6585 [3:15:08<44:46,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5352/6585 [3:15:10<44:43,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5353/6585 [3:15:13<45:00,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5354/6585 [3:15:15<44:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5355/6585 [3:15:17<44:42,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5356/6585 [3:15:19<44:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5357/6585 [3:15:21<44:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5358/6585 [3:15:24<44:45,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5359/6585 [3:15:26<44:39,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5360/6585 [3:15:28<44:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5361/6585 [3:15:30<44:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5362/6585 [3:15:32<44:19,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5363/6585 [3:15:34<44:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5364/6585 [3:15:37<44:48,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5365/6585 [3:15:39<44:44,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 81% 5366/6585 [3:15:41<44:41,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5367/6585 [3:15:43<44:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5368/6585 [3:15:45<44:20,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5369/6585 [3:15:48<44:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5370/6585 [3:15:50<44:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5371/6585 [3:15:52<44:17,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5372/6585 [3:15:54<44:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5373/6585 [3:15:56<44:12,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5374/6585 [3:15:59<44:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5375/6585 [3:16:01<44:06,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5376/6585 [3:16:03<44:10,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5377/6585 [3:16:05<44:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5378/6585 [3:16:07<43:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5379/6585 [3:16:09<43:56,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5380/6585 [3:16:12<43:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5381/6585 [3:16:14<43:58,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5382/6585 [3:16:16<43:50,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5383/6585 [3:16:18<43:56,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5384/6585 [3:16:20<44:02,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5385/6585 [3:16:23<43:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5386/6585 [3:16:25<43:43,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5387/6585 [3:16:27<43:38,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5388/6585 [3:16:29<43:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5389/6585 [3:16:31<43:54,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5390/6585 [3:16:34<43:38,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5391/6585 [3:16:36<43:39,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5392/6585 [3:16:38<43:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5393/6585 [3:16:40<43:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5394/6585 [3:16:42<43:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5395/6585 [3:16:45<43:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5396/6585 [3:16:47<43:21,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5397/6585 [3:16:49<43:11,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5398/6585 [3:16:51<43:00,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5399/6585 [3:16:53<42:57,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5400/6585 [3:16:55<43:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5401/6585 [3:16:58<42:53,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5402/6585 [3:17:00<42:50,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5403/6585 [3:17:02<42:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5404/6585 [3:17:04<42:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5405/6585 [3:17:06<42:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5406/6585 [3:17:08<42:51,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5407/6585 [3:17:11<42:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5408/6585 [3:17:13<42:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5409/6585 [3:17:15<42:28,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5410/6585 [3:17:17<42:46,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5411/6585 [3:17:19<42:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5412/6585 [3:17:22<42:30,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5413/6585 [3:17:24<42:32,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5414/6585 [3:17:26<42:31,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5415/6585 [3:17:28<42:50,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5416/6585 [3:17:30<42:45,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5417/6585 [3:17:33<42:45,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5418/6585 [3:17:35<42:34,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5419/6585 [3:17:37<42:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5420/6585 [3:17:39<42:38,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.1105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5421/6585 [3:17:41<42:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5422/6585 [3:17:43<42:21,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5423/6585 [3:17:46<42:12,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5424/6585 [3:17:48<42:10,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5425/6585 [3:17:50<42:17,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5426/6585 [3:17:52<42:10,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5427/6585 [3:17:54<42:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5428/6585 [3:17:57<42:05,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.1048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5429/6585 [3:17:59<42:03,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5430/6585 [3:18:01<42:08,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5431/6585 [3:18:03<42:05,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 82% 5432/6585 [3:18:05<42:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5433/6585 [3:18:07<42:00,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5434/6585 [3:18:10<41:49,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5435/6585 [3:18:12<41:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5436/6585 [3:18:14<42:07,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5437/6585 [3:18:16<41:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5438/6585 [3:18:18<41:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5439/6585 [3:18:21<41:45,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5440/6585 [3:18:23<41:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5441/6585 [3:18:25<41:56,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5442/6585 [3:18:27<41:46,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5443/6585 [3:18:29<41:38,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5444/6585 [3:18:32<41:34,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5445/6585 [3:18:34<41:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5446/6585 [3:18:36<41:42,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5447/6585 [3:18:38<41:30,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5448/6585 [3:18:40<41:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5449/6585 [3:18:42<41:17,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5450/6585 [3:18:45<41:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5451/6585 [3:18:47<41:41,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5452/6585 [3:18:49<41:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5453/6585 [3:18:51<41:14,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5454/6585 [3:18:53<41:12,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5455/6585 [3:18:56<41:06,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5456/6585 [3:18:58<41:19,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5457/6585 [3:19:00<41:12,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5458/6585 [3:19:02<41:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5459/6585 [3:19:04<41:06,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5460/6585 [3:19:07<40:56,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5461/6585 [3:19:09<40:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5462/6585 [3:19:11<40:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5463/6585 [3:19:13<40:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5464/6585 [3:19:15<40:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5465/6585 [3:19:17<40:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5466/6585 [3:19:20<40:33,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5467/6585 [3:19:22<40:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5468/6585 [3:19:24<40:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5469/6585 [3:19:26<40:52,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5470/6585 [3:19:28<40:43,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5471/6585 [3:19:31<40:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5472/6585 [3:19:33<40:53,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5473/6585 [3:19:35<40:42,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5474/6585 [3:19:37<40:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5475/6585 [3:19:39<40:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5476/6585 [3:19:42<40:19,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5477/6585 [3:19:44<40:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5478/6585 [3:19:46<40:21,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5479/6585 [3:19:48<40:17,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5480/6585 [3:19:50<40:10,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5481/6585 [3:19:52<39:59,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5482/6585 [3:19:55<40:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5483/6585 [3:19:57<40:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5484/6585 [3:19:59<40:09,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5485/6585 [3:20:01<40:08,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5486/6585 [3:20:03<39:58,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5487/6585 [3:20:06<40:11,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5488/6585 [3:20:08<40:07,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5489/6585 [3:20:10<40:09,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5490/6585 [3:20:12<39:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5491/6585 [3:20:14<39:57,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5492/6585 [3:20:17<40:09,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5493/6585 [3:20:19<40:20,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5494/6585 [3:20:21<40:07,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5495/6585 [3:20:23<39:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5496/6585 [3:20:25<39:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5497/6585 [3:20:28<39:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 83% 5498/6585 [3:20:30<39:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5499/6585 [3:20:32<39:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5500/6585 [3:20:34<39:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5501/6585 [3:20:36<39:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5502/6585 [3:20:39<39:44,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5503/6585 [3:20:41<40:07,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5504/6585 [3:20:43<39:55,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5505/6585 [3:20:45<39:54,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5506/6585 [3:20:47<39:49,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5507/6585 [3:20:50<39:55,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5508/6585 [3:20:52<40:07,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5509/6585 [3:20:54<39:56,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5510/6585 [3:20:56<39:56,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5511/6585 [3:20:59<39:38,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5512/6585 [3:21:01<39:23,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5513/6585 [3:21:03<39:26,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5514/6585 [3:21:05<39:10,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5515/6585 [3:21:07<39:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5516/6585 [3:21:09<38:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5517/6585 [3:21:12<38:49,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5518/6585 [3:21:14<38:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5519/6585 [3:21:16<38:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5520/6585 [3:21:18<38:43,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5521/6585 [3:21:20<38:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5522/6585 [3:21:23<38:28,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5523/6585 [3:21:25<38:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5524/6585 [3:21:27<38:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5525/6585 [3:21:29<38:26,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5526/6585 [3:21:31<38:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5527/6585 [3:21:33<38:26,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5528/6585 [3:21:36<38:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5529/6585 [3:21:38<38:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5530/6585 [3:21:40<38:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5531/6585 [3:21:42<38:24,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5532/6585 [3:21:44<38:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5533/6585 [3:21:47<38:31,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5534/6585 [3:21:49<38:21,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5535/6585 [3:21:51<38:10,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5536/6585 [3:21:53<38:03,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5537/6585 [3:21:55<37:55,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5538/6585 [3:21:57<37:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5539/6585 [3:22:00<38:06,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.5856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5540/6585 [3:22:02<38:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5541/6585 [3:22:04<37:54,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5542/6585 [3:22:06<37:51,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5543/6585 [3:22:08<37:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5544/6585 [3:22:11<38:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5545/6585 [3:22:13<38:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5546/6585 [3:22:15<37:57,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5547/6585 [3:22:17<37:45,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5548/6585 [3:22:19<37:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5549/6585 [3:22:21<37:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5550/6585 [3:22:24<37:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5551/6585 [3:22:26<37:28,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5552/6585 [3:22:28<37:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5553/6585 [3:22:30<37:21,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5554/6585 [3:22:32<37:32,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5555/6585 [3:22:35<37:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5556/6585 [3:22:37<37:34,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5557/6585 [3:22:39<37:24,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5558/6585 [3:22:41<37:19,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5559/6585 [3:22:43<37:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5560/6585 [3:22:45<37:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5561/6585 [3:22:48<37:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5562/6585 [3:22:50<37:16,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5563/6585 [3:22:52<37:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 84% 5564/6585 [3:22:54<37:14,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5565/6585 [3:22:56<37:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5566/6585 [3:22:59<37:09,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5567/6585 [3:23:01<37:06,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5568/6585 [3:23:03<36:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5569/6585 [3:23:05<36:56,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5570/6585 [3:23:07<37:09,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5571/6585 [3:23:10<36:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5572/6585 [3:23:12<36:43,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5573/6585 [3:23:14<36:42,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5574/6585 [3:23:16<36:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5575/6585 [3:23:18<36:47,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5576/6585 [3:23:20<36:38,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5577/6585 [3:23:23<36:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5578/6585 [3:23:25<36:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5579/6585 [3:23:27<36:25,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5580/6585 [3:23:29<36:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.6251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5581/6585 [3:23:31<36:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5582/6585 [3:23:33<36:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5583/6585 [3:23:36<36:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5584/6585 [3:23:38<36:17,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5585/6585 [3:23:40<36:31,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5586/6585 [3:23:42<36:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5587/6585 [3:23:44<36:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5588/6585 [3:23:47<36:13,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5589/6585 [3:23:49<36:06,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5590/6585 [3:23:51<36:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5591/6585 [3:23:53<36:13,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5592/6585 [3:23:55<36:05,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5593/6585 [3:23:57<36:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5594/6585 [3:24:00<35:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5595/6585 [3:24:02<35:54,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5596/6585 [3:24:04<35:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5597/6585 [3:24:06<35:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5598/6585 [3:24:08<35:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5599/6585 [3:24:11<35:59,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5600/6585 [3:24:13<35:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5601/6585 [3:24:15<36:08,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5602/6585 [3:24:17<35:59,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5603/6585 [3:24:19<35:53,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5604/6585 [3:24:22<35:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5605/6585 [3:24:24<35:49,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5606/6585 [3:24:26<35:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5607/6585 [3:24:28<35:46,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5608/6585 [3:24:30<35:37,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5609/6585 [3:24:33<35:31,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5610/6585 [3:24:35<35:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5611/6585 [3:24:37<35:46,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5612/6585 [3:24:39<35:36,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5613/6585 [3:24:41<35:22,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5614/6585 [3:24:43<35:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5615/6585 [3:24:46<35:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5616/6585 [3:24:48<35:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5617/6585 [3:24:50<35:20,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5618/6585 [3:24:52<35:12,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5619/6585 [3:24:54<35:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5620/6585 [3:24:57<34:56,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5621/6585 [3:24:59<35:07,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5622/6585 [3:25:01<35:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5623/6585 [3:25:03<35:00,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5624/6585 [3:25:05<34:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5625/6585 [3:25:07<34:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5626/6585 [3:25:10<34:55,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5627/6585 [3:25:12<34:55,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5628/6585 [3:25:14<35:11,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5629/6585 [3:25:16<35:16,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 85% 5630/6585 [3:25:19<35:18,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5631/6585 [3:25:21<35:11,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5632/6585 [3:25:23<35:08,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5633/6585 [3:25:25<35:02,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5634/6585 [3:25:27<34:50,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5635/6585 [3:25:30<34:38,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5636/6585 [3:25:32<34:59,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5637/6585 [3:25:34<35:11,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5638/6585 [3:25:36<35:11,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5639/6585 [3:25:39<35:02,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5640/6585 [3:25:41<34:50,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5641/6585 [3:25:43<34:54,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5642/6585 [3:25:45<35:05,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5643/6585 [3:25:47<35:09,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5644/6585 [3:25:50<35:13,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5645/6585 [3:25:52<35:03,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5646/6585 [3:25:54<34:44,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5647/6585 [3:25:56<34:48,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5648/6585 [3:25:59<34:37,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5649/6585 [3:26:01<34:23,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5650/6585 [3:26:03<34:05,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5651/6585 [3:26:05<33:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5652/6585 [3:26:07<34:03,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5653/6585 [3:26:09<34:16,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5654/6585 [3:26:12<34:01,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5655/6585 [3:26:14<34:09,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5656/6585 [3:26:16<33:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5657/6585 [3:26:18<34:13,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5658/6585 [3:26:20<34:06,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5659/6585 [3:26:23<33:58,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5660/6585 [3:26:25<33:51,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5661/6585 [3:26:27<33:39,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5662/6585 [3:26:29<33:51,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5663/6585 [3:26:31<33:47,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5664/6585 [3:26:34<33:38,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5665/6585 [3:26:36<33:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5666/6585 [3:26:38<33:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5667/6585 [3:26:40<33:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5668/6585 [3:26:42<33:39,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5669/6585 [3:26:45<33:32,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5670/6585 [3:26:47<33:34,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5671/6585 [3:26:49<33:28,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5672/6585 [3:26:51<33:25,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5673/6585 [3:26:53<33:35,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5674/6585 [3:26:56<33:30,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5675/6585 [3:26:58<33:22,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5676/6585 [3:27:00<33:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5677/6585 [3:27:02<33:09,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5678/6585 [3:27:04<33:17,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5679/6585 [3:27:07<33:05,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5680/6585 [3:27:09<33:08,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5681/6585 [3:27:11<33:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5682/6585 [3:27:13<32:59,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5683/6585 [3:27:15<33:13,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5684/6585 [3:27:18<33:01,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5685/6585 [3:27:20<33:01,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5686/6585 [3:27:22<32:49,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5687/6585 [3:27:24<32:43,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5688/6585 [3:27:26<33:00,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5689/6585 [3:27:29<32:55,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5690/6585 [3:27:31<32:56,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5691/6585 [3:27:33<32:41,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5692/6585 [3:27:35<32:49,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5693/6585 [3:27:37<32:55,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5694/6585 [3:27:40<32:50,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5695/6585 [3:27:42<32:39,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 86% 5696/6585 [3:27:44<32:34,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5697/6585 [3:27:46<32:28,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5698/6585 [3:27:48<32:46,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5699/6585 [3:27:51<32:50,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5700/6585 [3:27:53<32:40,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5701/6585 [3:27:55<32:27,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5702/6585 [3:27:57<32:20,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5703/6585 [3:28:00<32:34,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5704/6585 [3:28:02<32:25,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5705/6585 [3:28:04<32:20,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5706/6585 [3:28:06<32:19,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5707/6585 [3:28:08<32:20,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5708/6585 [3:28:11<32:26,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5709/6585 [3:28:13<32:18,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5710/6585 [3:28:15<32:15,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5711/6585 [3:28:17<32:01,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5712/6585 [3:28:19<31:57,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5713/6585 [3:28:22<31:52,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5714/6585 [3:28:24<31:51,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5715/6585 [3:28:26<31:43,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5716/6585 [3:28:28<31:38,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5717/6585 [3:28:30<31:32,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5718/6585 [3:28:32<31:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5719/6585 [3:28:35<31:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5720/6585 [3:28:37<31:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5721/6585 [3:28:39<31:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5722/6585 [3:28:41<31:17,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5723/6585 [3:28:43<31:19,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5724/6585 [3:28:46<31:39,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5725/6585 [3:28:48<31:50,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5726/6585 [3:28:50<31:41,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5727/6585 [3:28:52<31:26,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5728/6585 [3:28:54<31:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5729/6585 [3:28:57<31:30,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5730/6585 [3:28:59<31:23,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5731/6585 [3:29:01<31:22,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5732/6585 [3:29:03<31:12,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5733/6585 [3:29:05<31:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5734/6585 [3:29:08<31:07,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5735/6585 [3:29:10<31:03,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5736/6585 [3:29:12<30:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5737/6585 [3:29:14<30:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5738/6585 [3:29:16<30:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5739/6585 [3:29:18<30:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5740/6585 [3:29:21<30:57,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5741/6585 [3:29:23<31:05,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5742/6585 [3:29:25<30:58,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5743/6585 [3:29:27<30:45,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5744/6585 [3:29:29<30:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5745/6585 [3:29:32<30:36,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5746/6585 [3:29:34<30:37,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5747/6585 [3:29:36<30:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5748/6585 [3:29:38<30:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5749/6585 [3:29:40<30:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5750/6585 [3:29:43<30:24,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5751/6585 [3:29:45<30:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5752/6585 [3:29:47<30:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5753/6585 [3:29:49<30:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5754/6585 [3:29:51<30:06,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5755/6585 [3:29:53<30:12,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5756/6585 [3:29:56<30:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5757/6585 [3:29:58<30:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5758/6585 [3:30:00<29:58,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5759/6585 [3:30:02<29:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5760/6585 [3:30:04<30:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 87% 5761/6585 [3:30:07<29:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5762/6585 [3:30:09<29:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5763/6585 [3:30:11<29:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5764/6585 [3:30:13<29:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5765/6585 [3:30:15<29:52,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5766/6585 [3:30:17<29:46,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5767/6585 [3:30:20<29:42,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5768/6585 [3:30:22<29:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5769/6585 [3:30:24<29:33,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5770/6585 [3:30:26<29:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5771/6585 [3:30:28<29:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5772/6585 [3:30:30<29:27,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5773/6585 [3:30:33<29:25,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5774/6585 [3:30:35<29:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5775/6585 [3:30:37<29:39,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5776/6585 [3:30:39<29:34,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5777/6585 [3:30:41<29:22,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5778/6585 [3:30:44<29:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5779/6585 [3:30:46<29:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5780/6585 [3:30:48<29:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5781/6585 [3:30:50<29:34,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5782/6585 [3:30:52<29:24,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5783/6585 [3:30:55<29:11,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5784/6585 [3:30:57<29:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5785/6585 [3:30:59<29:03,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5786/6585 [3:31:01<29:10,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5787/6585 [3:31:03<29:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5788/6585 [3:31:05<29:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5789/6585 [3:31:08<29:01,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5790/6585 [3:31:10<28:54,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5791/6585 [3:31:12<29:12,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5792/6585 [3:31:14<29:01,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5793/6585 [3:31:16<28:52,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5794/6585 [3:31:19<28:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5795/6585 [3:31:21<28:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5796/6585 [3:31:23<28:44,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5797/6585 [3:31:25<28:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5798/6585 [3:31:27<28:39,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5799/6585 [3:31:30<28:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5800/6585 [3:31:32<28:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5801/6585 [3:31:34<28:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5802/6585 [3:31:36<28:45,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5803/6585 [3:31:38<28:36,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5804/6585 [3:31:41<28:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5805/6585 [3:31:43<28:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5806/6585 [3:31:45<28:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5807/6585 [3:31:47<28:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5808/6585 [3:31:49<28:20,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5809/6585 [3:31:51<28:16,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5810/6585 [3:31:54<28:16,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5811/6585 [3:31:56<28:10,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5812/6585 [3:31:58<28:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5813/6585 [3:32:00<28:07,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5814/6585 [3:32:02<28:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5815/6585 [3:32:05<28:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5816/6585 [3:32:07<28:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5817/6585 [3:32:09<27:56,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5818/6585 [3:32:11<27:54,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5819/6585 [3:32:13<27:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5820/6585 [3:32:15<27:43,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5821/6585 [3:32:18<27:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5822/6585 [3:32:20<27:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5823/6585 [3:32:22<27:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5824/6585 [3:32:24<27:30,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5825/6585 [3:32:26<27:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5826/6585 [3:32:28<27:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 88% 5827/6585 [3:32:31<27:24,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5828/6585 [3:32:33<27:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5829/6585 [3:32:35<27:17,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5830/6585 [3:32:37<27:17,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5831/6585 [3:32:39<27:14,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5832/6585 [3:32:41<27:10,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5833/6585 [3:32:44<27:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5834/6585 [3:32:46<27:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5835/6585 [3:32:48<27:10,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5836/6585 [3:32:50<27:04,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5837/6585 [3:32:52<27:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5838/6585 [3:32:55<27:06,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5839/6585 [3:32:57<27:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5840/6585 [3:32:59<27:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5841/6585 [3:33:01<27:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5842/6585 [3:33:03<27:00,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5843/6585 [3:33:05<26:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5844/6585 [3:33:08<26:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5845/6585 [3:33:10<26:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5846/6585 [3:33:12<26:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5847/6585 [3:33:14<26:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5848/6585 [3:33:16<26:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5849/6585 [3:33:18<26:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5850/6585 [3:33:21<26:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5851/6585 [3:33:23<26:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5852/6585 [3:33:25<26:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5853/6585 [3:33:27<26:44,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5854/6585 [3:33:29<26:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5855/6585 [3:33:32<26:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5856/6585 [3:33:34<26:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5857/6585 [3:33:36<26:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5858/6585 [3:33:38<26:31,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5859/6585 [3:33:40<26:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5860/6585 [3:33:42<26:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5861/6585 [3:33:45<26:04,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5862/6585 [3:33:47<26:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5863/6585 [3:33:49<26:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5864/6585 [3:33:51<26:00,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5865/6585 [3:33:53<26:03,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5866/6585 [3:33:55<26:02,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5867/6585 [3:33:58<26:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5868/6585 [3:34:00<25:58,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5869/6585 [3:34:02<25:56,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5870/6585 [3:34:04<25:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5871/6585 [3:34:06<25:44,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5872/6585 [3:34:08<25:42,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5873/6585 [3:34:11<25:38,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5874/6585 [3:34:13<25:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5875/6585 [3:34:15<25:35,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5876/6585 [3:34:17<25:30,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5877/6585 [3:34:19<25:32,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5878/6585 [3:34:21<25:31,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5879/6585 [3:34:24<25:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5880/6585 [3:34:26<25:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5881/6585 [3:34:28<25:31,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5882/6585 [3:34:30<25:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5883/6585 [3:34:32<25:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5884/6585 [3:34:35<25:21,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5885/6585 [3:34:37<25:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5886/6585 [3:34:39<25:24,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5887/6585 [3:34:41<25:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5888/6585 [3:34:43<25:09,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5889/6585 [3:34:45<25:06,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5890/6585 [3:34:48<25:03,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5891/6585 [3:34:50<25:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5892/6585 [3:34:52<24:51,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 89% 5893/6585 [3:34:54<25:01,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5894/6585 [3:34:56<24:57,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5895/6585 [3:34:58<24:59,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5896/6585 [3:35:01<24:56,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5897/6585 [3:35:03<24:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5898/6585 [3:35:05<24:46,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5899/6585 [3:35:07<24:39,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5900/6585 [3:35:09<24:39,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5901/6585 [3:35:11<24:39,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5902/6585 [3:35:13<24:36,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5903/6585 [3:35:16<24:30,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5904/6585 [3:35:18<24:28,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5905/6585 [3:35:20<24:36,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5906/6585 [3:35:22<24:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5907/6585 [3:35:24<24:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5908/6585 [3:35:27<24:38,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5909/6585 [3:35:29<24:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5910/6585 [3:35:31<24:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5911/6585 [3:35:33<24:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5912/6585 [3:35:35<24:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5913/6585 [3:35:37<24:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5914/6585 [3:35:40<24:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5915/6585 [3:35:42<24:15,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5916/6585 [3:35:44<24:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5917/6585 [3:35:46<24:08,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5918/6585 [3:35:48<24:02,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5919/6585 [3:35:50<23:59,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5920/6585 [3:35:53<24:01,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5921/6585 [3:35:55<24:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5922/6585 [3:35:57<24:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5923/6585 [3:35:59<24:14,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5924/6585 [3:36:01<24:15,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5925/6585 [3:36:04<24:19,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5926/6585 [3:36:06<24:21,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5927/6585 [3:36:08<24:16,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5928/6585 [3:36:10<24:13,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5929/6585 [3:36:13<24:09,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5930/6585 [3:36:15<24:11,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5931/6585 [3:36:17<24:16,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5932/6585 [3:36:19<24:02,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5933/6585 [3:36:21<23:49,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5934/6585 [3:36:24<23:41,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5935/6585 [3:36:26<23:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5936/6585 [3:36:28<23:41,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5937/6585 [3:36:30<23:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5938/6585 [3:36:32<23:25,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5939/6585 [3:36:34<23:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5940/6585 [3:36:37<23:15,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5941/6585 [3:36:39<23:13,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5942/6585 [3:36:41<23:08,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5943/6585 [3:36:43<23:03,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5944/6585 [3:36:45<23:02,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5945/6585 [3:36:47<23:02,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5946/6585 [3:36:49<23:00,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5947/6585 [3:36:52<22:57,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5948/6585 [3:36:54<22:59,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5949/6585 [3:36:56<22:54,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5950/6585 [3:36:58<22:49,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5951/6585 [3:37:00<22:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5952/6585 [3:37:03<23:00,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5953/6585 [3:37:05<22:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5954/6585 [3:37:07<22:47,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5955/6585 [3:37:09<22:40,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5956/6585 [3:37:11<22:34,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5957/6585 [3:37:13<22:33,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5958/6585 [3:37:15<22:30,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 90% 5959/6585 [3:37:18<22:33,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5960/6585 [3:37:20<22:30,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5961/6585 [3:37:22<22:29,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5962/6585 [3:37:24<22:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5963/6585 [3:37:26<22:28,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5964/6585 [3:37:28<22:24,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5965/6585 [3:37:31<22:19,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5966/6585 [3:37:33<22:18,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5967/6585 [3:37:35<22:24,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5968/6585 [3:37:37<22:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5969/6585 [3:37:39<22:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5970/6585 [3:37:41<22:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5971/6585 [3:37:44<22:13,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5972/6585 [3:37:46<22:15,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5973/6585 [3:37:48<22:09,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5974/6585 [3:37:50<22:08,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5975/6585 [3:37:52<22:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5976/6585 [3:37:55<22:02,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5977/6585 [3:37:57<21:56,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5978/6585 [3:37:59<21:56,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5979/6585 [3:38:01<21:49,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5980/6585 [3:38:03<21:47,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5981/6585 [3:38:05<21:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5982/6585 [3:38:07<21:46,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5983/6585 [3:38:10<21:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5984/6585 [3:38:12<21:46,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5985/6585 [3:38:14<21:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5986/6585 [3:38:16<21:37,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5987/6585 [3:38:18<21:37,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5988/6585 [3:38:21<21:36,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5989/6585 [3:38:23<21:33,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5990/6585 [3:38:25<21:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5991/6585 [3:38:27<21:29,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5992/6585 [3:38:29<21:27,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5993/6585 [3:38:31<21:22,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5994/6585 [3:38:34<21:25,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5995/6585 [3:38:36<21:21,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5996/6585 [3:38:38<21:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5997/6585 [3:38:40<21:11,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5998/6585 [3:38:42<21:10,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 5999/6585 [3:38:44<21:12,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6000/6585 [3:38:47<21:10,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6001/6585 [3:38:49<21:06,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6002/6585 [3:38:51<21:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6003/6585 [3:38:53<21:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6004/6585 [3:38:55<21:02,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6005/6585 [3:38:57<20:57,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6006/6585 [3:39:00<20:55,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6007/6585 [3:39:02<20:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6008/6585 [3:39:04<20:47,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6009/6585 [3:39:06<20:47,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6010/6585 [3:39:08<20:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6011/6585 [3:39:10<20:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6012/6585 [3:39:13<20:39,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6013/6585 [3:39:15<20:36,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6014/6585 [3:39:17<20:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6015/6585 [3:39:19<20:33,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6016/6585 [3:39:21<20:28,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6017/6585 [3:39:23<20:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6018/6585 [3:39:26<20:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6019/6585 [3:39:28<20:28,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6020/6585 [3:39:30<20:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6021/6585 [3:39:32<20:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6022/6585 [3:39:34<20:22,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6023/6585 [3:39:36<20:19,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6024/6585 [3:39:39<20:15,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 91% 6025/6585 [3:39:41<20:14,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6026/6585 [3:39:43<20:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6027/6585 [3:39:45<20:03,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6028/6585 [3:39:47<20:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6029/6585 [3:39:49<20:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6030/6585 [3:39:52<20:02,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6031/6585 [3:39:54<20:00,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6032/6585 [3:39:56<19:58,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6033/6585 [3:39:58<19:59,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6034/6585 [3:40:00<19:55,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6035/6585 [3:40:02<19:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6036/6585 [3:40:05<19:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6037/6585 [3:40:07<19:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6038/6585 [3:40:09<19:48,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6039/6585 [3:40:11<19:41,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6040/6585 [3:40:13<19:39,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6041/6585 [3:40:15<19:35,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6042/6585 [3:40:18<19:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6043/6585 [3:40:20<19:35,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6044/6585 [3:40:22<19:31,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6045/6585 [3:40:24<19:33,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6046/6585 [3:40:26<19:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6047/6585 [3:40:29<19:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6048/6585 [3:40:31<19:32,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6049/6585 [3:40:33<19:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6050/6585 [3:40:35<19:30,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6051/6585 [3:40:37<19:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6052/6585 [3:40:39<19:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6053/6585 [3:40:42<19:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6054/6585 [3:40:44<19:21,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6055/6585 [3:40:46<19:19,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6056/6585 [3:40:48<19:22,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6057/6585 [3:40:50<19:20,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6058/6585 [3:40:53<19:15,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6059/6585 [3:40:55<19:14,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6060/6585 [3:40:57<19:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6061/6585 [3:40:59<19:09,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6062/6585 [3:41:01<19:03,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6063/6585 [3:41:04<19:03,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6064/6585 [3:41:06<18:59,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6065/6585 [3:41:08<18:54,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6066/6585 [3:41:10<18:51,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6067/6585 [3:41:12<18:50,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6068/6585 [3:41:14<18:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6069/6585 [3:41:17<18:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6070/6585 [3:41:19<18:37,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6071/6585 [3:41:21<18:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6072/6585 [3:41:23<18:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6073/6585 [3:41:25<18:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6074/6585 [3:41:27<18:31,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6075/6585 [3:41:30<18:27,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6076/6585 [3:41:32<18:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6077/6585 [3:41:34<18:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6078/6585 [3:41:36<18:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6079/6585 [3:41:38<18:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6080/6585 [3:41:40<18:14,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6081/6585 [3:41:43<18:14,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6082/6585 [3:41:45<18:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6083/6585 [3:41:47<18:13,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6084/6585 [3:41:49<18:13,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6085/6585 [3:41:51<18:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.4519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6086/6585 [3:41:54<17:58,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6087/6585 [3:41:56<18:00,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6088/6585 [3:41:58<18:02,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6089/6585 [3:42:00<17:55,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6090/6585 [3:42:02<17:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 92% 6091/6585 [3:42:04<17:51,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6092/6585 [3:42:07<17:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6093/6585 [3:42:09<17:50,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6094/6585 [3:42:11<17:50,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6095/6585 [3:42:13<17:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6096/6585 [3:42:15<17:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6097/6585 [3:42:17<17:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6098/6585 [3:42:20<17:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6099/6585 [3:42:22<17:35,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6100/6585 [3:42:24<17:33,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6101/6585 [3:42:26<17:28,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6102/6585 [3:42:28<17:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6103/6585 [3:42:31<17:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6104/6585 [3:42:33<17:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6105/6585 [3:42:35<17:23,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6106/6585 [3:42:37<17:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6107/6585 [3:42:39<17:14,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6108/6585 [3:42:41<17:19,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6109/6585 [3:42:44<17:13,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6110/6585 [3:42:46<17:12,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6111/6585 [3:42:48<17:08,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6112/6585 [3:42:50<17:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6113/6585 [3:42:52<17:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6114/6585 [3:42:54<17:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6115/6585 [3:42:57<16:55,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6116/6585 [3:42:59<16:51,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6117/6585 [3:43:01<16:52,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6118/6585 [3:43:03<16:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6119/6585 [3:43:05<16:53,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6120/6585 [3:43:07<16:50,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6121/6585 [3:43:10<16:48,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6122/6585 [3:43:12<16:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6123/6585 [3:43:14<16:42,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6124/6585 [3:43:16<16:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6125/6585 [3:43:18<16:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6126/6585 [3:43:20<16:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6127/6585 [3:43:23<16:31,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6128/6585 [3:43:25<16:29,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6129/6585 [3:43:27<16:29,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6130/6585 [3:43:29<16:27,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6131/6585 [3:43:31<16:21,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6132/6585 [3:43:33<16:21,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6133/6585 [3:43:36<16:19,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6134/6585 [3:43:38<16:20,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6135/6585 [3:43:40<16:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6136/6585 [3:43:42<16:15,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6137/6585 [3:43:44<16:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6138/6585 [3:43:46<16:07,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6139/6585 [3:43:49<16:07,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6140/6585 [3:43:51<16:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6141/6585 [3:43:53<16:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6142/6585 [3:43:55<16:00,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6143/6585 [3:43:57<15:59,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6144/6585 [3:43:59<15:56,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6145/6585 [3:44:02<15:51,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6146/6585 [3:44:04<15:49,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6147/6585 [3:44:06<15:45,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6148/6585 [3:44:08<15:43,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6149/6585 [3:44:10<15:41,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6150/6585 [3:44:12<15:40,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6151/6585 [3:44:15<15:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6152/6585 [3:44:17<15:35,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6153/6585 [3:44:19<15:32,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6154/6585 [3:44:21<15:32,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6155/6585 [3:44:23<15:28,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 93% 6156/6585 [3:44:25<15:27,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6157/6585 [3:44:28<15:25,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6158/6585 [3:44:30<15:21,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6159/6585 [3:44:32<15:24,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6160/6585 [3:44:34<15:21,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6161/6585 [3:44:36<15:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6162/6585 [3:44:38<15:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6163/6585 [3:44:41<15:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6164/6585 [3:44:43<15:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6165/6585 [3:44:45<15:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6166/6585 [3:44:47<15:09,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6167/6585 [3:44:49<15:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6168/6585 [3:44:51<14:59,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6169/6585 [3:44:54<14:58,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6170/6585 [3:44:56<14:58,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6171/6585 [3:44:58<14:59,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6172/6585 [3:45:00<14:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6173/6585 [3:45:02<14:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6174/6585 [3:45:04<14:47,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6175/6585 [3:45:07<14:44,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6176/6585 [3:45:09<14:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6177/6585 [3:45:11<14:40,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6178/6585 [3:45:13<14:38,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6179/6585 [3:45:15<14:37,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6180/6585 [3:45:17<14:36,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6181/6585 [3:45:20<14:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6182/6585 [3:45:22<14:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6183/6585 [3:45:24<14:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6184/6585 [3:45:26<14:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6185/6585 [3:45:28<14:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6186/6585 [3:45:30<14:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6187/6585 [3:45:33<14:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6188/6585 [3:45:35<14:22,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6189/6585 [3:45:37<14:19,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6190/6585 [3:45:39<14:13,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6191/6585 [3:45:41<14:15,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6192/6585 [3:45:44<14:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6193/6585 [3:45:46<14:10,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6194/6585 [3:45:48<14:09,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6195/6585 [3:45:50<14:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6196/6585 [3:45:52<14:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6197/6585 [3:45:54<14:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6198/6585 [3:45:57<14:02,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6199/6585 [3:45:59<13:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6200/6585 [3:46:01<13:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6201/6585 [3:46:03<13:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6202/6585 [3:46:05<13:51,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6203/6585 [3:46:07<13:47,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6204/6585 [3:46:10<13:44,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6205/6585 [3:46:12<13:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6206/6585 [3:46:14<13:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6207/6585 [3:46:16<13:45,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6208/6585 [3:46:18<13:41,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6209/6585 [3:46:20<13:38,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6210/6585 [3:46:23<13:35,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6211/6585 [3:46:25<13:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6212/6585 [3:46:27<13:39,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6213/6585 [3:46:29<13:43,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6214/6585 [3:46:32<13:44,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6215/6585 [3:46:34<13:38,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6216/6585 [3:46:36<13:33,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6217/6585 [3:46:38<13:32,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6218/6585 [3:46:40<13:25,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6219/6585 [3:46:43<13:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6220/6585 [3:46:45<13:19,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6221/6585 [3:46:47<13:20,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 94% 6222/6585 [3:46:49<13:34,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6223/6585 [3:46:52<13:33,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6224/6585 [3:46:54<13:28,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6225/6585 [3:46:56<13:22,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6226/6585 [3:46:58<13:22,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6227/6585 [3:47:00<13:20,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6228/6585 [3:47:03<13:14,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6229/6585 [3:47:05<13:11,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6230/6585 [3:47:07<13:05,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6231/6585 [3:47:09<13:04,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6232/6585 [3:47:11<13:03,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6233/6585 [3:47:14<13:02,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6234/6585 [3:47:16<12:59,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6235/6585 [3:47:18<12:56,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6236/6585 [3:47:20<12:54,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6237/6585 [3:47:23<12:57,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6238/6585 [3:47:25<12:54,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6239/6585 [3:47:27<12:49,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6240/6585 [3:47:29<12:47,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6241/6585 [3:47:32<12:44,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6242/6585 [3:47:34<12:41,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6243/6585 [3:47:36<12:39,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6244/6585 [3:47:38<12:36,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6245/6585 [3:47:40<12:29,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6246/6585 [3:47:43<12:27,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6247/6585 [3:47:45<12:22,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6248/6585 [3:47:47<12:25,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6249/6585 [3:47:49<12:24,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6250/6585 [3:47:51<12:17,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6251/6585 [3:47:54<12:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6252/6585 [3:47:56<12:05,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6253/6585 [3:47:58<12:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6254/6585 [3:48:00<12:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6255/6585 [3:48:02<12:04,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6256/6585 [3:48:04<11:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6257/6585 [3:48:07<11:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6258/6585 [3:48:09<11:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6259/6585 [3:48:11<11:50,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6260/6585 [3:48:13<11:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6261/6585 [3:48:15<11:43,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6262/6585 [3:48:17<11:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6263/6585 [3:48:20<11:38,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6264/6585 [3:48:22<11:36,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6265/6585 [3:48:24<11:39,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6266/6585 [3:48:26<11:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6267/6585 [3:48:28<11:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6268/6585 [3:48:31<11:34,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6269/6585 [3:48:33<11:33,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6270/6585 [3:48:35<11:30,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6271/6585 [3:48:37<11:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6272/6585 [3:48:39<11:19,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6273/6585 [3:48:41<11:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6274/6585 [3:48:44<11:17,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6275/6585 [3:48:46<11:22,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6276/6585 [3:48:48<11:18,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6277/6585 [3:48:50<11:13,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6278/6585 [3:48:52<11:13,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6279/6585 [3:48:55<11:13,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6280/6585 [3:48:57<11:11,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6281/6585 [3:48:59<11:14,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6282/6585 [3:49:01<11:10,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6283/6585 [3:49:04<11:07,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6284/6585 [3:49:06<11:03,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6285/6585 [3:49:08<11:00,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6286/6585 [3:49:10<10:58,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6287/6585 [3:49:12<10:56,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 95% 6288/6585 [3:49:15<10:55,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6289/6585 [3:49:17<10:54,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6290/6585 [3:49:19<10:53,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6291/6585 [3:49:21<10:50,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6292/6585 [3:49:23<10:46,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6293/6585 [3:49:26<10:43,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6294/6585 [3:49:28<10:42,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6295/6585 [3:49:30<10:40,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6296/6585 [3:49:32<10:36,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6297/6585 [3:49:34<10:34,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6298/6585 [3:49:37<10:31,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6299/6585 [3:49:39<10:30,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6300/6585 [3:49:41<10:28,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6301/6585 [3:49:43<10:23,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6302/6585 [3:49:45<10:19,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6303/6585 [3:49:48<10:19,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6304/6585 [3:49:50<10:18,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6305/6585 [3:49:52<10:14,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6306/6585 [3:49:54<10:10,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6307/6585 [3:49:56<10:05,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6308/6585 [3:49:59<10:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6309/6585 [3:50:01<10:02,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6310/6585 [3:50:03<09:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6311/6585 [3:50:05<09:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6312/6585 [3:50:07<09:53,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6313/6585 [3:50:09<09:48,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6314/6585 [3:50:11<09:45,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6315/6585 [3:50:14<09:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6316/6585 [3:50:16<09:44,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6317/6585 [3:50:18<09:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6318/6585 [3:50:20<09:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6319/6585 [3:50:22<09:37,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6320/6585 [3:50:25<09:35,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6321/6585 [3:50:27<09:34,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6322/6585 [3:50:29<09:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6323/6585 [3:50:31<09:34,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6324/6585 [3:50:33<09:33,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6325/6585 [3:50:36<09:33,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6326/6585 [3:50:38<09:29,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6327/6585 [3:50:40<09:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6328/6585 [3:50:42<09:18,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6329/6585 [3:50:44<09:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6330/6585 [3:50:46<09:14,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.7352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6331/6585 [3:50:49<09:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6332/6585 [3:50:51<09:09,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6333/6585 [3:50:53<09:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6334/6585 [3:50:55<09:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6335/6585 [3:50:57<09:04,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6336/6585 [3:50:59<09:03,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6337/6585 [3:51:02<09:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6338/6585 [3:51:04<08:56,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6339/6585 [3:51:06<08:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6340/6585 [3:51:08<08:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6341/6585 [3:51:10<08:51,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6342/6585 [3:51:13<08:48,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6343/6585 [3:51:15<08:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6344/6585 [3:51:17<08:43,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6345/6585 [3:51:19<08:43,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6346/6585 [3:51:21<08:44,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6347/6585 [3:51:23<08:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6348/6585 [3:51:26<08:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6349/6585 [3:51:28<08:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6350/6585 [3:51:30<08:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6351/6585 [3:51:32<08:31,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6352/6585 [3:51:34<08:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6353/6585 [3:51:37<08:24,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 96% 6354/6585 [3:51:39<08:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6355/6585 [3:51:41<08:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6356/6585 [3:51:43<08:18,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6357/6585 [3:51:45<08:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6358/6585 [3:51:47<08:12,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6359/6585 [3:51:50<08:09,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6360/6585 [3:51:52<08:06,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6361/6585 [3:51:54<08:06,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6362/6585 [3:51:56<08:05,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6363/6585 [3:51:58<08:05,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6364/6585 [3:52:00<08:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6365/6585 [3:52:03<07:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6366/6585 [3:52:05<07:59,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6367/6585 [3:52:07<07:56,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6368/6585 [3:52:09<07:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6369/6585 [3:52:11<07:50,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6370/6585 [3:52:14<07:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6371/6585 [3:52:16<07:47,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6372/6585 [3:52:18<07:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6373/6585 [3:52:20<07:41,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6374/6585 [3:52:22<07:39,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6375/6585 [3:52:24<07:36,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6376/6585 [3:52:27<07:36,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6377/6585 [3:52:29<07:35,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6378/6585 [3:52:31<07:31,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6379/6585 [3:52:33<07:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6380/6585 [3:52:35<07:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6381/6585 [3:52:38<07:24,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6382/6585 [3:52:40<07:22,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6383/6585 [3:52:42<07:20,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6384/6585 [3:52:44<07:18,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6385/6585 [3:52:46<07:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6386/6585 [3:52:48<07:13,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6387/6585 [3:52:51<07:12,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6388/6585 [3:52:53<07:10,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6389/6585 [3:52:55<07:11,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6390/6585 [3:52:57<07:07,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6391/6585 [3:52:59<07:03,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6392/6585 [3:53:02<07:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6393/6585 [3:53:04<06:59,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6394/6585 [3:53:06<06:55,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6395/6585 [3:53:08<06:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6396/6585 [3:53:10<06:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6397/6585 [3:53:12<06:50,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6398/6585 [3:53:15<06:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6399/6585 [3:53:17<06:44,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6400/6585 [3:53:19<06:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6401/6585 [3:53:21<06:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6402/6585 [3:53:23<06:40,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6403/6585 [3:53:26<06:38,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6404/6585 [3:53:28<06:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6405/6585 [3:53:30<06:33,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6406/6585 [3:53:32<06:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6407/6585 [3:53:34<06:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6408/6585 [3:53:36<06:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6409/6585 [3:53:39<06:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6410/6585 [3:53:41<06:20,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6411/6585 [3:53:43<06:16,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6412/6585 [3:53:45<06:14,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6413/6585 [3:53:47<06:12,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6414/6585 [3:53:49<06:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6415/6585 [3:53:52<06:08,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6416/6585 [3:53:54<06:05,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6417/6585 [3:53:56<06:06,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6418/6585 [3:53:58<06:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6419/6585 [3:54:00<06:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 97% 6420/6585 [3:54:03<06:01,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6421/6585 [3:54:05<05:58,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6422/6585 [3:54:07<05:55,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6423/6585 [3:54:09<05:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6424/6585 [3:54:11<05:50,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6425/6585 [3:54:13<05:48,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6426/6585 [3:54:16<05:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6427/6585 [3:54:18<05:43,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6428/6585 [3:54:20<05:40,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6429/6585 [3:54:22<05:37,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6430/6585 [3:54:24<05:35,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6431/6585 [3:54:26<05:32,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6432/6585 [3:54:29<05:29,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6433/6585 [3:54:31<05:28,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6434/6585 [3:54:33<05:28,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6435/6585 [3:54:35<05:24,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6436/6585 [3:54:37<05:22,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6437/6585 [3:54:39<05:19,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6438/6585 [3:54:42<05:19,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6439/6585 [3:54:44<05:17,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6440/6585 [3:54:46<05:14,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6441/6585 [3:54:48<05:11,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6442/6585 [3:54:50<05:08,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6443/6585 [3:54:52<05:04,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6444/6585 [3:54:55<05:03,  2.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6445/6585 [3:54:57<05:01,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6446/6585 [3:54:59<04:59,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6447/6585 [3:55:01<04:57,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6448/6585 [3:55:03<04:55,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6449/6585 [3:55:05<04:53,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6450/6585 [3:55:08<04:53,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6451/6585 [3:55:10<04:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6452/6585 [3:55:12<04:51,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6453/6585 [3:55:14<04:49,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6454/6585 [3:55:16<04:46,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6455/6585 [3:55:19<04:44,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6456/6585 [3:55:21<04:40,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6457/6585 [3:55:23<04:37,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6458/6585 [3:55:25<04:35,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6459/6585 [3:55:27<04:35,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6460/6585 [3:55:29<04:32,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6461/6585 [3:55:32<04:30,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6462/6585 [3:55:34<04:27,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6463/6585 [3:55:36<04:26,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6464/6585 [3:55:38<04:23,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6465/6585 [3:55:40<04:22,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6466/6585 [3:55:42<04:19,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6467/6585 [3:55:45<04:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6468/6585 [3:55:47<04:14,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6469/6585 [3:55:49<04:13,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6470/6585 [3:55:51<04:10,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6471/6585 [3:55:53<04:08,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6472/6585 [3:55:56<04:06,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6473/6585 [3:55:58<04:03,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6474/6585 [3:56:00<04:01,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6475/6585 [3:56:02<03:59,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6476/6585 [3:56:04<03:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6477/6585 [3:56:06<03:54,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6478/6585 [3:56:09<03:52,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6479/6585 [3:56:11<03:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6480/6585 [3:56:13<03:47,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6481/6585 [3:56:15<03:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6482/6585 [3:56:17<03:43,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6483/6585 [3:56:19<03:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6484/6585 [3:56:22<03:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6485/6585 [3:56:24<03:36,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 98% 6486/6585 [3:56:26<03:35,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6487/6585 [3:56:28<03:32,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6488/6585 [3:56:30<03:30,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6489/6585 [3:56:32<03:28,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6490/6585 [3:56:35<03:27,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6491/6585 [3:56:37<03:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6492/6585 [3:56:39<03:23,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6493/6585 [3:56:41<03:21,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6494/6585 [3:56:43<03:18,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6495/6585 [3:56:46<03:16,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6496/6585 [3:56:48<03:14,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6497/6585 [3:56:50<03:11,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6498/6585 [3:56:52<03:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6499/6585 [3:56:54<03:07,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6500/6585 [3:56:57<03:06,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6501/6585 [3:56:59<03:04,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.4698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6502/6585 [3:57:01<03:02,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6503/6585 [3:57:03<03:00,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6504/6585 [3:57:05<02:58,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6505/6585 [3:57:08<02:55,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6506/6585 [3:57:10<02:54,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6507/6585 [3:57:12<02:51,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6508/6585 [3:57:14<02:48,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6509/6585 [3:57:16<02:46,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6510/6585 [3:57:18<02:43,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6511/6585 [3:57:21<02:42,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6512/6585 [3:57:23<02:39,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6513/6585 [3:57:25<02:37,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6514/6585 [3:57:27<02:34,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6515/6585 [3:57:29<02:32,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6516/6585 [3:57:32<02:31,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6517/6585 [3:57:34<02:29,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6518/6585 [3:57:36<02:26,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6519/6585 [3:57:38<02:24,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6520/6585 [3:57:40<02:21,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6521/6585 [3:57:43<02:19,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6522/6585 [3:57:45<02:17,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6523/6585 [3:57:47<02:16,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6524/6585 [3:57:49<02:13,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6525/6585 [3:57:51<02:11,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6526/6585 [3:57:54<02:09,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6527/6585 [3:57:56<02:07,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6528/6585 [3:57:58<02:05,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.8396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6529/6585 [3:58:00<02:02,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6530/6585 [3:58:02<02:00,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6531/6585 [3:58:04<01:57,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6532/6585 [3:58:07<01:56,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6533/6585 [3:58:09<01:54,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6534/6585 [3:58:11<01:51,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6535/6585 [3:58:13<01:49,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6536/6585 [3:58:15<01:47,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6537/6585 [3:58:18<01:45,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6538/6585 [3:58:20<01:43,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6539/6585 [3:58:22<01:42,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6540/6585 [3:58:24<01:39,  2.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6541/6585 [3:58:27<01:36,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6542/6585 [3:58:29<01:35,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6543/6585 [3:58:31<01:32,  2.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6544/6585 [3:58:33<01:29,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6545/6585 [3:58:35<01:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6546/6585 [3:58:37<01:24,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(3.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6547/6585 [3:58:40<01:22,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.8614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6548/6585 [3:58:42<01:20,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6549/6585 [3:58:44<01:17,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6550/6585 [3:58:46<01:15,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6551/6585 [3:58:48<01:13,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            " 99% 6552/6585 [3:58:50<01:11,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6553/6585 [3:58:53<01:09,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6554/6585 [3:58:55<01:07,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6555/6585 [3:58:57<01:05,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6556/6585 [3:58:59<01:02,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6557/6585 [3:59:01<01:00,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6558/6585 [3:59:04<00:59,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6559/6585 [3:59:06<00:56,  2.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6560/6585 [3:59:08<00:54,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6561/6585 [3:59:10<00:52,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6562/6585 [3:59:12<00:49,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6563/6585 [3:59:14<00:47,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6564/6585 [3:59:17<00:45,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6565/6585 [3:59:19<00:43,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6566/6585 [3:59:21<00:41,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6567/6585 [3:59:23<00:39,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6568/6585 [3:59:25<00:37,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(1.9956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6569/6585 [3:59:28<00:35,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6570/6585 [3:59:30<00:33,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.3144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6571/6585 [3:59:32<00:31,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.5776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6572/6585 [3:59:34<00:29,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.9275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6573/6585 [3:59:37<00:27,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6574/6585 [3:59:39<00:25,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6575/6585 [3:59:41<00:22,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6576/6585 [3:59:44<00:20,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6577/6585 [3:59:46<00:18,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6578/6585 [3:59:48<00:15,  2.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6579/6585 [3:59:50<00:13,  2.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6580/6585 [3:59:53<00:11,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.7651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6581/6585 [3:59:55<00:09,  2.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.1630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6582/6585 [3:59:57<00:06,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.4644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6583/6585 [4:00:00<00:04,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.2181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6584/6585 [4:00:02<00:02,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "tensor(2.6402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100% 6585/6585 [4:00:04<00:00,  2.19s/it]\n",
            "Saving the dataset (1/1 shards): 100% 6585/6585 [00:00<00:00, 913101.42 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 6585/6585 [00:00<00:00, 1013038.87 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch ./ft_llms/llms_finetune.py --refer \\\n",
        "--output_dir ./ft_llms/falcon/wikitext/refer/ \\\n",
        "--block_size 128 --eval_steps 100 --save_epochs 100 --log_steps 100 \\\n",
        "-d wikitext -m tiiuae/falcon-rw-1b --packing --use_dataset_cache \\\n",
        "-e 2 -b 2 -lr 5e-5 --gradient_accumulation_steps 1 \\\n",
        "--train_sta_idx=0 --train_end_idx=2000 --eval_sta_idx=0 --eval_end_idx=500 \\\n",
        "--dataset_config_name wikitext-2-raw-v1"
      ],
      "metadata": {
        "id": "om69Us0J9uDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81654098-d1bb-4116-a3f8-08a834603e15"
      },
      "id": "om69Us0J9uDx",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-05-05 22:28:35.219092: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-05 22:28:35.236218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746484115.257395   66063 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746484115.263923   66063 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-05 22:28:35.284855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "trainable params: 12582912 || all params: 1324208128 || trainable%: 0.9502216255842224\n",
            "Folder './cache/wikitext/wikitext-2-raw-v1' already exists.\n",
            "Converting train dataset to ChatML: 100% 2000/2000 [00:00<00:00, 49554.63 examples/s]\n",
            "Adding EOS to train dataset: 100% 2000/2000 [00:00<00:00, 30083.19 examples/s]\n",
            "Tokenizing train dataset: 100% 2000/2000 [00:01<00:00, 1817.28 examples/s]\n",
            "Truncating train dataset: 100% 2000/2000 [00:00<00:00, 327334.76 examples/s]\n",
            "Converting eval dataset to ChatML: 100% 500/500 [00:00<00:00, 45001.33 examples/s]\n",
            "Adding EOS to eval dataset: 100% 500/500 [00:00<00:00, 29059.31 examples/s]\n",
            "Tokenizing eval dataset: 100% 500/500 [00:00<00:00, 1775.35 examples/s]\n",
            "Truncating eval dataset: 100% 500/500 [00:00<00:00, 206331.37 examples/s]\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\n",
            "{'loss': 2.8246, 'grad_norm': 0.4808482527732849, 'learning_rate': 4.7525e-05, 'epoch': 0.1}\n",
            "  5% 100/2000 [00:08<02:20, 13.56it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 29.77it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 25.10it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.68it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.90it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.44it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.25it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 22.06it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 22.06it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 22.00it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.96it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.94it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.88it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.90it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.79it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.83it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.87it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.84it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.89it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.83it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.77it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.79it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.80it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.75it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.78it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.76it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.75it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.85it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.90it/s]\u001b[A\n",
            " 70% 88/125 [00:03<00:01, 21.88it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.88it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.90it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.86it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.84it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.86it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.87it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.86it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.83it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.74it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.66it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.58it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 3.075256824493408, 'eval_runtime': 5.7252, 'eval_samples_per_second': 87.333, 'eval_steps_per_second': 21.833, 'eval_num_tokens': 25784.0, 'eval_mean_token_accuracy': 0.42528125, 'epoch': 0.1}\n",
            "  5% 100/2000 [00:13<02:20, 13.56it/s]\n",
            "100% 125/125 [00:05<00:00, 21.64it/s]\u001b[A\n",
            "{'loss': 2.5838, 'grad_norm': 0.6595472097396851, 'learning_rate': 4.5025000000000003e-05, 'epoch': 0.2}\n",
            " 10% 200/2000 [00:22<02:17, 13.13it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.79it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.47it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.88it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.24it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.01it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.67it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.74it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.75it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.70it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.52it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.44it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.48it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.53it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.64it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.56it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.54it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.44it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.32it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.37it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.46it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.50it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.53it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.27it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.23it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.34it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.32it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.38it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.32it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.30it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.14it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.31it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.40it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.38it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.38it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.29it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.21it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.19it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 3.00256609916687, 'eval_runtime': 5.8419, 'eval_samples_per_second': 85.588, 'eval_steps_per_second': 21.397, 'eval_num_tokens': 51563.0, 'eval_mean_token_accuracy': 0.4341875, 'epoch': 0.2}\n",
            " 10% 200/2000 [00:28<02:17, 13.13it/s]\n",
            "100% 125/125 [00:05<00:00, 21.26it/s]\u001b[A\n",
            "{'loss': 2.4977, 'grad_norm': 0.6309692859649658, 'learning_rate': 4.2525000000000004e-05, 'epoch': 0.3}\n",
            " 15% 300/2000 [00:36<02:09, 13.08it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.30it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.85it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.64it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.08it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:05, 21.55it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.30it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.34it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.31it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.24it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.13it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.18it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.10it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:04, 21.16it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.21it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.18it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.08it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.10it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.16it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 20.96it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 20.95it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.07it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.08it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.13it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.16it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.11it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.06it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.19it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.16it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.13it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.14it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.15it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.06it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.08it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.07it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.06it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.13it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.08it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.15it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.16it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.04it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.959670305252075, 'eval_runtime': 5.9253, 'eval_samples_per_second': 84.384, 'eval_steps_per_second': 21.096, 'eval_num_tokens': 77273.0, 'eval_mean_token_accuracy': 0.43975, 'epoch': 0.3}\n",
            " 15% 300/2000 [00:42<02:09, 13.08it/s]\n",
            "100% 125/125 [00:05<00:00, 20.97it/s]\u001b[A\n",
            "{'loss': 2.4672, 'grad_norm': 0.6352295279502869, 'learning_rate': 4.0025000000000004e-05, 'epoch': 0.4}\n",
            " 20% 400/2000 [00:50<02:00, 13.28it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.81it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 23.83it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.61it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 21.94it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:05, 21.75it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.59it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.58it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.54it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.39it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.38it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.31it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.37it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:04, 21.19it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.33it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.36it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.31it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.22it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.26it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.29it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.21it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.28it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.37it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.35it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.37it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.39it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.35it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.37it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.31it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.35it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.34it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.34it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.46it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.39it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.40it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.34it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.36it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.36it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.953761577606201, 'eval_runtime': 5.8659, 'eval_samples_per_second': 85.238, 'eval_steps_per_second': 21.31, 'eval_num_tokens': 103057.0, 'eval_mean_token_accuracy': 0.441125, 'epoch': 0.4}\n",
            " 20% 400/2000 [00:56<02:00, 13.28it/s]\n",
            "100% 125/125 [00:05<00:00, 21.29it/s]\u001b[A\n",
            "{'loss': 2.4787, 'grad_norm': 0.674766480922699, 'learning_rate': 3.7525e-05, 'epoch': 0.5}\n",
            " 25% 500/2000 [01:04<01:52, 13.35it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.13it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.49it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.19it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.44it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.14it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 22.02it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.85it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.77it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.74it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.71it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.51it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.51it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.56it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.58it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.62it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.69it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.65it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.52it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.52it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.63it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.69it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.71it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.65it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.39it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.52it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.50it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.66it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.69it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.66it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.63it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.48it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.53it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.40it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.45it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.9422948360443115, 'eval_runtime': 5.7991, 'eval_samples_per_second': 86.22, 'eval_steps_per_second': 21.555, 'eval_num_tokens': 128839.0, 'eval_mean_token_accuracy': 0.442453125, 'epoch': 0.5}\n",
            " 25% 500/2000 [01:10<01:52, 13.35it/s]\n",
            "100% 125/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            "{'loss': 2.4441, 'grad_norm': 0.7471148371696472, 'learning_rate': 3.5025000000000004e-05, 'epoch': 0.6}\n",
            " 30% 600/2000 [01:18<01:44, 13.38it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 29.06it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.60it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.16it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.50it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.19it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.78it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.77it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.76it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.73it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.69it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.64it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.62it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.55it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.59it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.62it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.66it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.67it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.56it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.50it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.51it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.49it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.52it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.42it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.52it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.61it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.58it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.67it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.63it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.60it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.62it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.55it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.9275457859039307, 'eval_runtime': 5.799, 'eval_samples_per_second': 86.222, 'eval_steps_per_second': 21.555, 'eval_num_tokens': 154616.0, 'eval_mean_token_accuracy': 0.44371875, 'epoch': 0.6}\n",
            " 30% 600/2000 [01:24<01:44, 13.38it/s]\n",
            "100% 125/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            "{'loss': 2.4109, 'grad_norm': 1.0181245803833008, 'learning_rate': 3.2525e-05, 'epoch': 0.7}\n",
            " 35% 700/2000 [01:32<01:36, 13.44it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.89it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.40it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.14it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.45it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.08it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.84it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.80it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.84it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.85it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.73it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.61it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.68it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.70it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.81it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.85it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.77it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.71it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.50it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.55it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.60it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.68it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.75it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.77it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.72it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.71it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.66it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.66it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.67it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.65it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.65it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.59it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.59it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.55it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.64it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.69it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.71it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.65it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.9285876750946045, 'eval_runtime': 5.7733, 'eval_samples_per_second': 86.605, 'eval_steps_per_second': 21.651, 'eval_num_tokens': 180401.0, 'eval_mean_token_accuracy': 0.4436875, 'epoch': 0.7}\n",
            " 35% 700/2000 [01:38<01:36, 13.44it/s]\n",
            "100% 125/125 [00:05<00:00, 21.69it/s]\u001b[A\n",
            "{'loss': 2.3791, 'grad_norm': 0.8852084279060364, 'learning_rate': 3.0025000000000005e-05, 'epoch': 0.8}\n",
            " 40% 800/2000 [01:46<01:28, 13.56it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.80it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.57it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.93it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.44it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.91it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.60it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.69it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.75it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.80it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.77it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.75it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.67it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.59it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.62it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.73it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.82it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.78it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.66it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.68it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.65it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.54it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.62it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.67it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.69it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.70it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.65it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.61it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.58it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.67it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.75it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.79it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.78it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.72it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.71it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.64it/s]\u001b[A\n",
            " 87% 109/125 [00:04<00:00, 21.66it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.75it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.76it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.77it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.70it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.9273736476898193, 'eval_runtime': 5.7732, 'eval_samples_per_second': 86.607, 'eval_steps_per_second': 21.652, 'eval_num_tokens': 206190.0, 'eval_mean_token_accuracy': 0.444703125, 'epoch': 0.8}\n",
            " 40% 800/2000 [01:52<01:28, 13.56it/s]\n",
            "100% 125/125 [00:05<00:00, 21.67it/s]\u001b[A\n",
            "{'loss': 2.3817, 'grad_norm': 0.8579737544059753, 'learning_rate': 2.7525e-05, 'epoch': 0.9}\n",
            " 45% 900/2000 [02:00<01:24, 13.09it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.77it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.56it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.31it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.69it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.21it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.97it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.89it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.94it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.87it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.75it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.72it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.55it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.54it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.53it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.64it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.71it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.42it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.31it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.45it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.53it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.63it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.58it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.36it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.42it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.52it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.56it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.63it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.50it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.55it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.62it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.62it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.65it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.63it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.926182508468628, 'eval_runtime': 5.7931, 'eval_samples_per_second': 86.309, 'eval_steps_per_second': 21.577, 'eval_num_tokens': 231975.0, 'eval_mean_token_accuracy': 0.444109375, 'epoch': 0.9}\n",
            " 45% 900/2000 [02:06<01:24, 13.09it/s]\n",
            "100% 125/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            "{'loss': 2.3761, 'grad_norm': 0.7572703957557678, 'learning_rate': 2.5025e-05, 'epoch': 1.0}\n",
            " 50% 1000/2000 [02:14<01:16, 13.04it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.81it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.00it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.02it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.24it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.81it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.57it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.72it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.57it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.42it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.40it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.38it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.25it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:04, 21.24it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.30it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.28it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.41it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.50it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.50it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.24it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.32it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.41it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.38it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.39it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.39it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.31it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.17it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.37it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.34it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.39it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.45it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.25it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.28it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.35it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.47it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.39it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.922095537185669, 'eval_runtime': 5.8509, 'eval_samples_per_second': 85.457, 'eval_steps_per_second': 21.364, 'eval_num_tokens': 257761.0, 'eval_mean_token_accuracy': 0.444390625, 'epoch': 1.0}\n",
            " 50% 1000/2000 [02:20<01:16, 13.04it/s]\n",
            "100% 125/125 [00:05<00:00, 21.36it/s]\u001b[A\n",
            "{'loss': 2.3119, 'grad_norm': 1.0178816318511963, 'learning_rate': 2.2525000000000002e-05, 'epoch': 1.1}\n",
            " 55% 1100/2000 [02:28<01:09, 12.91it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 29.07it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.69it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.08it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.37it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.82it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.64it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.66it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.74it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.71it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.65it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.50it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.45it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.42it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.46it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.52it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.56it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.23it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.31it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.29it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.31it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.44it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.51it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.49it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.44it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.46it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.32it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.38it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.48it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.52it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.45it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.42it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9296319484710693, 'eval_runtime': 5.8244, 'eval_samples_per_second': 85.846, 'eval_steps_per_second': 21.461, 'eval_num_tokens': 283547.0, 'eval_mean_token_accuracy': 0.444625, 'epoch': 1.1}\n",
            " 55% 1100/2000 [02:34<01:09, 12.91it/s]\n",
            "100% 125/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            "{'loss': 2.3325, 'grad_norm': 0.765878438949585, 'learning_rate': 2.0025000000000002e-05, 'epoch': 1.2}\n",
            " 60% 1200/2000 [02:42<01:01, 13.09it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.79it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.54it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.28it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.59it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.28it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.83it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.78it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.87it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.71it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.65it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.55it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.28it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.30it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.47it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.55it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.50it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.30it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:03, 21.31it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.40it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.55it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.64it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.64it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.52it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.50it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.52it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.59it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.52it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.56it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.47it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.58it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.61it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.52it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.39it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9290292263031006, 'eval_runtime': 5.8082, 'eval_samples_per_second': 86.085, 'eval_steps_per_second': 21.521, 'eval_num_tokens': 309330.0, 'eval_mean_token_accuracy': 0.445046875, 'epoch': 1.2}\n",
            " 60% 1200/2000 [02:48<01:01, 13.09it/s]\n",
            "100% 125/125 [00:05<00:00, 21.38it/s]\u001b[A\n",
            "{'loss': 2.3409, 'grad_norm': 0.7935420870780945, 'learning_rate': 1.7525e-05, 'epoch': 1.3}\n",
            " 65% 1300/2000 [02:57<00:53, 13.16it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 29.35it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.58it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.89it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.10it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.98it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.80it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.75it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.81it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.69it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.65it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.49it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.51it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.46it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.55it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.53it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.64it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.67it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.64it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.63it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.42it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.56it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.61it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.63it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.63it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.62it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.56it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.52it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.48it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.54it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.45it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.37it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.46it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.55it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.38it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.51it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9250705242156982, 'eval_runtime': 5.813, 'eval_samples_per_second': 86.014, 'eval_steps_per_second': 21.503, 'eval_num_tokens': 335114.0, 'eval_mean_token_accuracy': 0.444953125, 'epoch': 1.3}\n",
            " 65% 1300/2000 [03:02<00:53, 13.16it/s]\n",
            "100% 125/125 [00:05<00:00, 21.34it/s]\u001b[A\n",
            "{'loss': 2.3847, 'grad_norm': 0.7758726477622986, 'learning_rate': 1.5025000000000001e-05, 'epoch': 1.4}\n",
            " 70% 1400/2000 [03:11<00:44, 13.43it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.96it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.46it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.99it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.34it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.08it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.86it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.81it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.85it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.65it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.49it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.45it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.40it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.50it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.50it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.54it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.61it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.56it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.44it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.29it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.48it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.48it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.54it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.65it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.41it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.52it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.56it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.41it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.49it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.54it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.51it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.30it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.37it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.46it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.55it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.46it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.925314426422119, 'eval_runtime': 5.8158, 'eval_samples_per_second': 85.972, 'eval_steps_per_second': 21.493, 'eval_num_tokens': 360898.0, 'eval_mean_token_accuracy': 0.44534375, 'epoch': 1.4}\n",
            " 70% 1400/2000 [03:17<00:44, 13.43it/s]\n",
            "100% 125/125 [00:05<00:00, 21.45it/s]\u001b[A\n",
            "{'loss': 2.337, 'grad_norm': 0.8323556780815125, 'learning_rate': 1.2525000000000001e-05, 'epoch': 1.5}\n",
            " 75% 1500/2000 [03:25<00:37, 13.43it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.09it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.13it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.85it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.39it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.90it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.73it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.79it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.74it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.67it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.58it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.56it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.50it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.50it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.56it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.60it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.60it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.53it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.45it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.48it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.68it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.65it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.56it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.62it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.56it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.54it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.59it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.60it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.61it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.54it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.58it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.54it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.47it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9256088733673096, 'eval_runtime': 5.8069, 'eval_samples_per_second': 86.105, 'eval_steps_per_second': 21.526, 'eval_num_tokens': 386676.0, 'eval_mean_token_accuracy': 0.445828125, 'epoch': 1.5}\n",
            " 75% 1500/2000 [03:31<00:37, 13.43it/s]\n",
            "100% 125/125 [00:05<00:00, 21.41it/s]\u001b[A\n",
            "{'loss': 2.2985, 'grad_norm': 0.668171226978302, 'learning_rate': 1.0025000000000001e-05, 'epoch': 1.6}\n",
            " 80% 1600/2000 [03:39<00:29, 13.45it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.06it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.17it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:04, 23.05it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.45it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.95it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.82it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.87it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.75it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.56it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.62it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.68it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.67it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.67it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.61it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.40it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.49it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.54it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.47it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.53it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.47it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.55it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.58it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.56it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.57it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.59it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.52it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.52it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.58it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.45it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.45it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.40it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.41it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.52it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.42it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.43it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.44it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.59it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9234628677368164, 'eval_runtime': 5.8103, 'eval_samples_per_second': 86.054, 'eval_steps_per_second': 21.513, 'eval_num_tokens': 412464.0, 'eval_mean_token_accuracy': 0.446328125, 'epoch': 1.6}\n",
            " 80% 1600/2000 [03:45<00:29, 13.45it/s]\n",
            "100% 125/125 [00:05<00:00, 21.64it/s]\u001b[A\n",
            "{'loss': 2.3471, 'grad_norm': 0.832061767578125, 'learning_rate': 7.525e-06, 'epoch': 1.7}\n",
            " 85% 1700/2000 [03:53<00:22, 13.12it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 27.87it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.23it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.98it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.34it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 21.85it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.76it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.84it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.79it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.66it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.63it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.61it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.56it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.40it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.55it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.58it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.53it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.49it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.44it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.56it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.60it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.64it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.67it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.58it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.55it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.61it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.68it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.39it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.59it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.60it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.50it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.53it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.53it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.58it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.34it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.46it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.51it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.47it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9248886108398438, 'eval_runtime': 5.8063, 'eval_samples_per_second': 86.113, 'eval_steps_per_second': 21.528, 'eval_num_tokens': 438245.0, 'eval_mean_token_accuracy': 0.44646875, 'epoch': 1.7}\n",
            " 85% 1700/2000 [03:59<00:22, 13.12it/s]\n",
            "100% 125/125 [00:05<00:00, 21.53it/s]\u001b[A\n",
            "{'loss': 2.3449, 'grad_norm': 0.8228864073753357, 'learning_rate': 5.025e-06, 'epoch': 1.8}\n",
            " 90% 1800/2000 [04:07<00:14, 13.65it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.17it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.35it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.98it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:04, 22.46it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.12it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.88it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.84it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.79it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.71it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.57it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.50it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.62it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.62it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.54it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.49it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.51it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.48it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.50it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.52it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.41it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.40it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.47it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.53it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.62it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.59it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.62it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.59it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.59it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.43it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.46it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.56it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.56it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.52it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.54it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.48it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.53it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.57it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.47it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.57it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9227242469787598, 'eval_runtime': 5.8092, 'eval_samples_per_second': 86.07, 'eval_steps_per_second': 21.518, 'eval_num_tokens': 463962.0, 'eval_mean_token_accuracy': 0.446453125, 'epoch': 1.8}\n",
            " 90% 1800/2000 [04:13<00:14, 13.65it/s]\n",
            "100% 125/125 [00:05<00:00, 21.45it/s]\u001b[A\n",
            "{'loss': 2.3131, 'grad_norm': 0.7089601755142212, 'learning_rate': 2.5250000000000004e-06, 'epoch': 1.9}\n",
            " 95% 1900/2000 [04:21<00:07, 13.54it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 26.99it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:05, 23.54it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.41it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 21.98it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:05, 21.79it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.57it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.66it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.50it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.46it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.45it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.50it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.30it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.46it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.53it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.46it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.42it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.44it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.52it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.39it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.35it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.51it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.57it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.47it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.54it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:02, 21.36it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.37it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.37it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.21it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.26it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.36it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.41it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.49it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.41it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.41it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.47it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.37it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9245898723602295, 'eval_runtime': 5.8484, 'eval_samples_per_second': 85.494, 'eval_steps_per_second': 21.374, 'eval_num_tokens': 489745.0, 'eval_mean_token_accuracy': 0.44609375, 'epoch': 1.9}\n",
            " 95% 1900/2000 [04:27<00:07, 13.54it/s]\n",
            "100% 125/125 [00:05<00:00, 21.35it/s]\u001b[A\n",
            "{'loss': 2.3163, 'grad_norm': 0.8294031620025635, 'learning_rate': 2.5000000000000002e-08, 'epoch': 2.0}\n",
            "100% 2000/2000 [04:35<00:00, 13.45it/s]\n",
            "  0% 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 4/125 [00:00<00:04, 28.79it/s]\u001b[A\n",
            "  6% 7/125 [00:00<00:04, 24.75it/s]\u001b[A\n",
            "  8% 10/125 [00:00<00:05, 22.97it/s]\u001b[A\n",
            " 10% 13/125 [00:00<00:05, 22.30it/s]\u001b[A\n",
            " 13% 16/125 [00:00<00:04, 22.00it/s]\u001b[A\n",
            " 15% 19/125 [00:00<00:04, 21.82it/s]\u001b[A\n",
            " 18% 22/125 [00:00<00:04, 21.83it/s]\u001b[A\n",
            " 20% 25/125 [00:01<00:04, 21.88it/s]\u001b[A\n",
            " 22% 28/125 [00:01<00:04, 21.88it/s]\u001b[A\n",
            " 25% 31/125 [00:01<00:04, 21.76it/s]\u001b[A\n",
            " 27% 34/125 [00:01<00:04, 21.50it/s]\u001b[A\n",
            " 30% 37/125 [00:01<00:04, 21.55it/s]\u001b[A\n",
            " 32% 40/125 [00:01<00:03, 21.55it/s]\u001b[A\n",
            " 34% 43/125 [00:01<00:03, 21.59it/s]\u001b[A\n",
            " 37% 46/125 [00:02<00:03, 21.57it/s]\u001b[A\n",
            " 39% 49/125 [00:02<00:03, 21.64it/s]\u001b[A\n",
            " 42% 52/125 [00:02<00:03, 21.62it/s]\u001b[A\n",
            " 44% 55/125 [00:02<00:03, 21.59it/s]\u001b[A\n",
            " 46% 58/125 [00:02<00:03, 21.52it/s]\u001b[A\n",
            " 49% 61/125 [00:02<00:02, 21.54it/s]\u001b[A\n",
            " 51% 64/125 [00:02<00:02, 21.38it/s]\u001b[A\n",
            " 54% 67/125 [00:03<00:02, 21.49it/s]\u001b[A\n",
            " 56% 70/125 [00:03<00:02, 21.51it/s]\u001b[A\n",
            " 58% 73/125 [00:03<00:02, 21.49it/s]\u001b[A\n",
            " 61% 76/125 [00:03<00:02, 21.43it/s]\u001b[A\n",
            " 63% 79/125 [00:03<00:02, 21.45it/s]\u001b[A\n",
            " 66% 82/125 [00:03<00:01, 21.50it/s]\u001b[A\n",
            " 68% 85/125 [00:03<00:01, 21.37it/s]\u001b[A\n",
            " 70% 88/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 73% 91/125 [00:04<00:01, 21.38it/s]\u001b[A\n",
            " 75% 94/125 [00:04<00:01, 21.47it/s]\u001b[A\n",
            " 78% 97/125 [00:04<00:01, 21.30it/s]\u001b[A\n",
            " 80% 100/125 [00:04<00:01, 21.44it/s]\u001b[A\n",
            " 82% 103/125 [00:04<00:01, 21.45it/s]\u001b[A\n",
            " 85% 106/125 [00:04<00:00, 21.47it/s]\u001b[A\n",
            " 87% 109/125 [00:05<00:00, 21.50it/s]\u001b[A\n",
            " 90% 112/125 [00:05<00:00, 21.55it/s]\u001b[A\n",
            " 92% 115/125 [00:05<00:00, 21.62it/s]\u001b[A\n",
            " 94% 118/125 [00:05<00:00, 21.62it/s]\u001b[A\n",
            " 97% 121/125 [00:05<00:00, 21.65it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 2.9238455295562744, 'eval_runtime': 5.8055, 'eval_samples_per_second': 86.125, 'eval_steps_per_second': 21.531, 'eval_num_tokens': 515522.0, 'eval_mean_token_accuracy': 0.44653125, 'epoch': 2.0}\n",
            "100% 2000/2000 [04:41<00:00, 13.45it/s]\n",
            "100% 125/125 [00:05<00:00, 21.67it/s]\u001b[A\n",
            "{'train_runtime': 282.184, 'train_samples_per_second': 14.175, 'train_steps_per_second': 7.088, 'train_loss': 2.408540283203125, 'num_tokens': 515522.0, 'mean_token_accuracy': 0.44834397265315057, 'epoch': 2.0}\n",
            "100% 2000/2000 [04:42<00:00,  7.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run SPV-MIA"
      ],
      "metadata": {
        "id": "pT9KrvIT-ZhF"
      },
      "id": "pT9KrvIT-ZhF"
    },
    {
      "cell_type": "code",
      "source": [
        "!python attack.py"
      ],
      "metadata": {
        "id": "zG96TTKK-ibT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774521e4-714c-4ffe-ddd2-db6bbf33634e"
      },
      "id": "zG96TTKK-ibT",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-05 22:42:34.944682: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-05 22:42:34.960977: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746484954.982030   69665 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746484954.988470   69665 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-05 22:42:35.009345: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "05/05/2025 22:42:46 - INFO - __main__ - Successfully load models\n",
            "05/05/2025 22:42:46 - INFO - __main__ - Pad token id is None, setting to eos token id...\n",
            "Folder './cache/wikitext/wikitext-2-raw-v1' already exists.\n",
            "05/05/2025 22:43:01 - INFO - __main__ - Successfully load datasets!\n",
            "config.json: 100% 1.21k/1.21k [00:00<00:00, 9.33MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "05/05/2025 22:43:02 - WARNING - huggingface_hub.file_download - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 892M/892M [00:01<00:00, 503MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 1.06MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 1.82MB/s]\n",
            "tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 3.28MB/s]\n",
            "05/05/2025 22:43:09 - INFO - attack.attack_model - Preparing data...\n",
            "05/05/2025 22:43:09 - INFO - attack.attack_model - Generating feature vectors for member data...\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "WARNING: 1 texts have no fills. Trying again [attempt 1].\n",
            "100% 1/1 [05:10<00:00, 310.61s/it]\n",
            "05/05/2025 22:48:19 - INFO - attack.attack_model - Generating feature vectors for non-member data...\n",
            "100% 1/1 [05:12<00:00, 312.76s/it]\n",
            "05/05/2025 22:53:32 - INFO - attack.attack_model - Saving feature vectors...\n",
            "05/05/2025 22:53:32 - INFO - attack.attack_model - Data preparation complete.\n",
            "05/05/2025 22:53:32 - INFO - attack.attack_model - AUC on the target model: 0.9952\n",
            "05/05/2025 22:53:32 - INFO - attack.attack_model - ASR on the target model: 0.96\n",
            "05/05/2025 22:53:32 - INFO - attack.attack_model - TPR@1%FPR on the target model: 0.0\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load ROC curve data\n",
        "data = np.load(\"/content/ANeurIPS2024_SPV-MIA/cache/wikitext/wikitext-2-raw-v1/attack_data_tiiuae/falcon-rw-1b@wikitext/roc_stat.npz\")\n",
        "fpr = data[\"fpr\"]\n",
        "tpr = data[\"tpr\"]\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {np.round(np.trapz(tpr, fpr), 4)})')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label=\"Random guess\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve – Statistical Membership Inference Attack\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Mark TPR@1%FPR\n",
        "fpr_1_index = np.argmin(np.abs(fpr - 0.01))\n",
        "plt.scatter(fpr[fpr_1_index], tpr[fpr_1_index], color='red', label=f'TPR@1%FPR: {tpr[fpr_1_index]:.3f}')\n",
        "plt.legend()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"roc_stat.png\", dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "ZwGsi1ORdKk8",
        "outputId": "4655d3bb-e095-4eec-c1e5-eb36e66c3345"
      },
      "id": "ZwGsi1ORdKk8",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-791e3dee5835>:11: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  plt.plot(fpr, tpr, label=f'ROC curve (AUC = {np.round(np.trapz(tpr, fpr), 4)})')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}